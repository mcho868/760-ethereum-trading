{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fda4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (6.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: stable-baselines3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: pyarrow in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: ta in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from plotly) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from stable-baselines3) (2.8.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from stable-baselines3) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: filelock in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install numpy pandas matplotlib seaborn plotly scikit-learn stable-baselines3 gymnasium pyarrow ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c748fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ PAPER-BASED DATA PREPROCESSING\n",
      "================================\n",
      "Following 'Reinforcement Learning Pair Trading: A Dynamic Scaling Approach'\n",
      "   MA Period: 60, Window: 120\n",
      "   Thresholds: Open=2.0, Close=0.5\n",
      "   Simplified approach: 3 values vs 32+ complex features\n",
      "\n",
      "üìÅ Loading data...\n",
      "   Data loaded: 1928080 rows\n",
      "   Date range: 2022-01-01 00:00:00+00:00 to 2025-08-31 23:59:00+00:00\n",
      "   üìä Calculating pseudo-spread signals...\n",
      "      Z-score range: [-10.32, 10.36]\n",
      "   üìç Calculating trading zones...\n",
      "\n",
      "   üéØ Zone distribution:\n",
      "     NEUTRAL_LONG: 582263 (30.2%)\n",
      "     CLOSE: 582227 (30.2%)\n",
      "     NEUTRAL_SHORT: 579862 (30.1%)\n",
      "     LONG: 95065 (4.9%)\n",
      "     SHORT: 88663 (4.6%)\n",
      "\n",
      "‚úÇÔ∏è  Splitting data for paper-based training...\n",
      "   Train data: 1542464 timesteps\n",
      "   Test data: 385616 timesteps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    144\u001b[39m train_df[export_cols].to_csv(train_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m, float_format=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m test_df[export_cols].to_csv(test_path,   index=\u001b[38;5;28;01mFalse\u001b[39;00m, float_format=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%.6f\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    146\u001b[39m \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexport_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexport_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%.6f\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ PAPER-BASED PREPROCESSING COMPLETE!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Exported paper-based signals to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:320\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    317\u001b[39m slicer = \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[32m    318\u001b[39m df = \u001b[38;5;28mself\u001b[39m.obj.iloc[slicer]\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/frame.py:1410\u001b[39m, in \u001b[36mDataFrame._get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_values_for_csv\u001b[39m(\n\u001b[32m   1401\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1402\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1408\u001b[39m ) -> Self:\n\u001b[32m   1409\u001b[39m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1410\u001b[39m     mgr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[32m   1418\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(mgr, axes=mgr.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:466\u001b[39m, in \u001b[36mBaseBlockManager.get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_values_for_csv\u001b[39m(\n\u001b[32m    460\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m, quoting=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    461\u001b[39m ) -> Self:\n\u001b[32m    462\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    463\u001b[39m \u001b[33;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[32m    464\u001b[39m \u001b[33;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[32m    465\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget_values_for_csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:806\u001b[39m, in \u001b[36mBlock.get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m    801\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_values_for_csv\u001b[39m(\n\u001b[32m    803\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m, quoting=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    804\u001b[39m ) -> Block:\n\u001b[32m    805\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     result = \u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    808\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    809\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    810\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    811\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    812\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    814\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.make_block(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7918\u001b[39m, in \u001b[36mget_values_for_csv\u001b[39m\u001b[34m(values, date_format, na_rep, quoting, float_format, decimal)\u001b[39m\n\u001b[32m   7908\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformats\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FloatArrayFormatter\n\u001b[32m   7910\u001b[39m formatter = FloatArrayFormatter(\n\u001b[32m   7911\u001b[39m     values,\n\u001b[32m   7912\u001b[39m     na_rep=na_rep,\n\u001b[32m   (...)\u001b[39m\u001b[32m   7916\u001b[39m     fixed_width=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   7917\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m7918\u001b[39m res = \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result_as_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7919\u001b[39m res = res.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   7920\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1439\u001b[39m, in \u001b[36mFloatArrayFormatter.get_result_as_array\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1436\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1437\u001b[39m     float_format = \u001b[38;5;28;01mlambda\u001b[39;00m value: \u001b[38;5;28mself\u001b[39m.float_format % value\n\u001b[32m-> \u001b[39m\u001b[32m1439\u001b[39m formatted_values = \u001b[43mformat_values_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_width:\n\u001b[32m   1442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted_values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1413\u001b[39m, in \u001b[36mFloatArrayFormatter.get_result_as_array.<locals>.format_values_with\u001b[39m\u001b[34m(float_format)\u001b[39m\n\u001b[32m   1411\u001b[39m     values = format_complex_with_na_rep(values, formatter, na_rep)\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1413\u001b[39m     values = \u001b[43mformat_with_na_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_width:\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_complex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1353\u001b[39m, in \u001b[36mFloatArrayFormatter.get_result_as_array.<locals>.format_with_na_rep\u001b[39m\u001b[34m(values, formatter, na_rep)\u001b[39m\n\u001b[32m   1349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat_with_na_rep\u001b[39m(values: ArrayLike, formatter: Callable, na_rep: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1350\u001b[39m     mask = isna(values)\n\u001b[32m   1351\u001b[39m     formatted = np.array(\n\u001b[32m   1352\u001b[39m         [\n\u001b[32m-> \u001b[39m\u001b[32m1353\u001b[39m             \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m m \u001b[38;5;28;01melse\u001b[39;00m na_rep\n\u001b[32m   1354\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m val, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values.ravel(), mask.ravel())\n\u001b[32m   1355\u001b[39m         ]\n\u001b[32m   1356\u001b[39m     ).reshape(values.shape)\n\u001b[32m   1357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1312\u001b[39m, in \u001b[36mFloatArrayFormatter._value_formatter.<locals>.base_formatter\u001b[39m\u001b[34m(v)\u001b[39m\n\u001b[32m   1306\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m float_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[32m   1307\u001b[39m \u001b[38;5;66;03m# error: \"str\" not callable\u001b[39;00m\n\u001b[32m   1308\u001b[39m \u001b[38;5;66;03m# error: Unexpected keyword argument \"value\" for \"__call__\" of\u001b[39;00m\n\u001b[32m   1309\u001b[39m \u001b[38;5;66;03m# \"EngFormatter\"\u001b[39;00m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1311\u001b[39m     float_format(value=v)  \u001b[38;5;66;03m# type: ignore[operator,call-arg]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1312\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.na_rep\n\u001b[32m   1314\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:457\u001b[39m, in \u001b[36mnotna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnotna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    381\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[33;03m    Detect non-missing values for an array-like object.\u001b[39;00m\n\u001b[32m    383\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    455\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    456\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     res = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    458\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mbool\u001b[39m):\n\u001b[32m    459\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/core/dtypes/missing.py:201\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    186\u001b[39m \u001b[33;03mDetect missing values, treating None, NaN or NA as null. Infinite\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[33;03mvalues will also be treated as null if inf_as_na is True.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    198\u001b[39m \u001b[33;03mboolean ndarray or boolean\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(obj):\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibmissing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchecknull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCMultiIndex):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33misna is not defined for MultiIndex\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================== Paper-Based Signal Generation =====================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "\n",
    "# Paper-Based Configuration (from research paper)\n",
    "PATH = \"../ETHUSDT_1m_with_indicators.parquet\"\n",
    "TS_COL = \"ts\"\n",
    "PRICE_COL = \"close\"\n",
    "\n",
    "# Signal parameters (from research paper)\n",
    "MA_PERIOD = 60                 # Moving average period for pseudo-spread\n",
    "WINDOW_SIZE = 120              # Window for z-score normalization  \n",
    "OPEN_THRESHOLD = 2.0           # Z-score threshold to open positions\n",
    "CLOSE_THRESHOLD = 0.5          # Z-score threshold to close positions\n",
    "\n",
    "# Trading parameters (optimized from methodology)\n",
    "SEED_MONEY = 10000.0\n",
    "FEE_RATE = 0.0001              # Reduced from 0.0005 to enable trading\n",
    "SLIPPAGE = 0.0001              # Reduced from 0.0002  \n",
    "TRANSACTION_PENALTY_RATE = 0.00005  # Reduced from 0.001\n",
    "ACTION_REWARD_SCALE = 0.1      # Increased from 0.01\n",
    "\n",
    "OUTPUT_DIR = \"./processed_data_paper\"\n",
    "\n",
    "print(\"üî¨ PAPER-BASED DATA PREPROCESSING\")\n",
    "print(\"================================\")\n",
    "print(\"Following 'Reinforcement Learning Pair Trading: A Dynamic Scaling Approach'\")\n",
    "print(f\"   MA Period: {MA_PERIOD}, Window: {WINDOW_SIZE}\")\n",
    "print(f\"   Thresholds: Open={OPEN_THRESHOLD}, Close={CLOSE_THRESHOLD}\")\n",
    "print(f\"   Simplified approach: 3 values vs 32+ complex features\")\n",
    "\n",
    "class TradingZone(Enum):\n",
    "    \"\"\"Trading zones based on z-score thresholds (from paper)\"\"\"\n",
    "    LONG_ZONE = 0      # Z-score < -open_threshold (price below MA - buy signal)\n",
    "    NEUTRAL_LONG = 1   # -open_threshold <= Z-score < -close_threshold  \n",
    "    CLOSE_ZONE = 2     # -close_threshold <= Z-score <= close_threshold\n",
    "    NEUTRAL_SHORT = 3  # close_threshold < Z-score <= open_threshold\n",
    "    SHORT_ZONE = 4     # Z-score > open_threshold (price above MA - sell signal)\n",
    "\n",
    "def calculate_pseudo_spread(prices: pd.Series, ma_period: int, window_size: int) -> pd.DataFrame:\n",
    "    \"\"\"Calculate pseudo-spread following research paper methodology\"\"\"\n",
    "    print(f\"   üìä Calculating pseudo-spread signals...\")\n",
    "    \n",
    "    df_signals = pd.DataFrame()\n",
    "    \n",
    "    # Step 1: Calculate moving average (pseudo-spread baseline)\n",
    "    ma = prices.rolling(window=ma_period, min_periods=1).mean()\n",
    "     \n",
    "    # Step 2: Calculate spread (price deviation from MA)\n",
    "    spread = prices - ma\n",
    "    \n",
    "    # Step 3: Normalize spread using z-score over rolling window\n",
    "    spread_mean = spread.rolling(window=window_size, min_periods=1).mean()\n",
    "    spread_std = spread.rolling(window=window_size, min_periods=1).std()\n",
    "    z_score = (spread - spread_mean) / (spread_std + 1e-8)  # Avoid division by zero\n",
    "    z_score = z_score.fillna(0)  # Fill NaN with neutral value\n",
    "    \n",
    "    # Store signals\n",
    "    df_signals['price'] = prices\n",
    "    df_signals['ma'] = ma\n",
    "    df_signals['spread'] = spread\n",
    "    df_signals['z_score'] = z_score\n",
    "    \n",
    "    print(f\"      Z-score range: [{z_score.min():.2f}, {z_score.max():.2f}]\")\n",
    "    \n",
    "    return df_signals\n",
    "\n",
    "def calculate_trading_zone(z_score: float, open_threshold: float, close_threshold: float) -> int:\n",
    "    \"\"\"Calculate trading zone based on z-score thresholds\"\"\"\n",
    "    if z_score > open_threshold:\n",
    "        return TradingZone.SHORT_ZONE.value  # Price above MA - sell signal\n",
    "    elif z_score > close_threshold:\n",
    "        return TradingZone.NEUTRAL_SHORT.value\n",
    "    elif z_score >= -close_threshold:\n",
    "        return TradingZone.CLOSE_ZONE.value  # Near MA - close positions\n",
    "    elif z_score >= -open_threshold:\n",
    "        return TradingZone.NEUTRAL_LONG.value\n",
    "    else:\n",
    "        return TradingZone.LONG_ZONE.value   # Price below MA - buy signal\n",
    "\n",
    "# ===================== Load and Process Data =====================\n",
    "print(\"\\nüìÅ Loading data...\")\n",
    "df = pd.read_parquet(PATH)\n",
    "df = df.reset_index()\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.sort_values(TS_COL).reset_index(drop=True)\n",
    "\n",
    "# Clean price data\n",
    "df[PRICE_COL] = pd.to_numeric(df[PRICE_COL], errors='coerce')\n",
    "df = df.dropna(subset=[PRICE_COL])\n",
    "df = df[df[PRICE_COL] > 0]\n",
    "\n",
    "print(f\"   Data loaded: {len(df)} rows\")\n",
    "print(f\"   Date range: {pd.to_datetime(df[TS_COL], unit='s').min()} to {pd.to_datetime(df[TS_COL], unit='s').max()}\")\n",
    "\n",
    "# ===================== Calculate Paper-Based Signals =====================\n",
    "signals_df = calculate_pseudo_spread(df[PRICE_COL], MA_PERIOD, WINDOW_SIZE)\n",
    "\n",
    "# Add zones\n",
    "print(f\"   üìç Calculating trading zones...\")\n",
    "signals_df['zone'] = signals_df['z_score'].apply(\n",
    "    lambda x: calculate_trading_zone(x, OPEN_THRESHOLD, CLOSE_THRESHOLD)\n",
    ")\n",
    "\n",
    "# Merge signals back to dataframe\n",
    "df = pd.concat([df.reset_index(drop=True), signals_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Show zone distribution\n",
    "zone_names = {\n",
    "    TradingZone.LONG_ZONE.value: 'LONG',\n",
    "    TradingZone.NEUTRAL_LONG.value: 'NEUTRAL_LONG', \n",
    "    TradingZone.CLOSE_ZONE.value: 'CLOSE',\n",
    "    TradingZone.NEUTRAL_SHORT.value: 'NEUTRAL_SHORT',\n",
    "    TradingZone.SHORT_ZONE.value: 'SHORT'\n",
    "}\n",
    "df['zone_name'] = df['zone'].map(zone_names)\n",
    "zone_counts = df['zone_name'].value_counts()\n",
    "print(f\"\\n   üéØ Zone distribution:\")\n",
    "for zone, count in zone_counts.items():\n",
    "    print(f\"     {zone}: {count} ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# ===================== Split Data (Paper-Based Approach) =====================\n",
    "print(f\"\\n‚úÇÔ∏è  Splitting data for paper-based training...\")\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df  = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"   Train data: {len(train_df)} timesteps\")\n",
    "print(f\"   Test data: {len(test_df)} timesteps\")\n",
    "\n",
    "# Paper-based features: only the essential signals\n",
    "paper_features = ['z_score', 'zone']  # Simplified from 32+ features to 2!\n",
    "export_cols = [TS_COL, PRICE_COL] + paper_features + ['zone_name']\n",
    "\n",
    "# ===================== Export Paper-Based Data =====================\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(OUTPUT_DIR, \"train_paper.csv\")\n",
    "test_path  = os.path.join(OUTPUT_DIR, \"test_paper.csv\")\n",
    "combo_path = os.path.join(OUTPUT_DIR, \"combined_paper.csv\")\n",
    "\n",
    "train_df[export_cols].to_csv(train_path, index=False, float_format=\"%.6f\")\n",
    "test_df[export_cols].to_csv(test_path,   index=False, float_format=\"%.6f\")\n",
    "pd.concat([train_df[export_cols], test_df[export_cols]], ignore_index=True)\\\n",
    "  .to_csv(combo_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(f\"\\n‚úÖ PAPER-BASED PREPROCESSING COMPLETE!\")\n",
    "print(f\"   Exported paper-based signals to: {OUTPUT_DIR}\")\n",
    "print(f\"   Features: {paper_features} (vs 32+ in original)\")\n",
    "print(f\"   Files: train_paper.csv, test_paper.csv, combined_paper.csv\")\n",
    "print(f\"   Key improvement: Dramatically simplified signal processing\")\n",
    "\n",
    "# Store paper-based features for environment\n",
    "feat_cols_paper = paper_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1253c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== ENHANCED TRADING ENVIRONMENT - FUNDAMENTAL FIXES =====================\n",
    "from typing import Dict, Optional, Tuple, Any\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüöÄ IMPLEMENTING COMPREHENSIVE FIXES FOR STATIC POSITION PROBLEM\")\n",
    "print(\"================================================================\")\n",
    "print(\"üîß FUNDAMENTAL FIXES BEING APPLIED:\")\n",
    "print(\"   1. ‚öñÔ∏è  REBALANCED REWARDS: Action rewards 50x larger vs portfolio rewards\")\n",
    "print(\"   2. üö´ ANTI-STATIC PENALTIES: Penalize unchanged positions over time\")\n",
    "print(\"   3. üéØ IMPROVED ZONE INCENTIVES: Balanced, compelling zone-based rewards\")\n",
    "print(\"   4. üí∏ REDUCED TRANSACTION COSTS: Make trading economically viable\")\n",
    "print(\"   5. üìä ENHANCED OBSERVATIONS: Add momentum/change indicators\")\n",
    "\n",
    "# ENHANCED PARAMETERS - MAJOR REBALANCING\n",
    "ENHANCED_SEED_MONEY = 10000.0\n",
    "ENHANCED_FEE_RATE = 0.00005           # REDUCED: 50% lower than original  \n",
    "ENHANCED_SLIPPAGE = 0.00005           # REDUCED: 50% lower than original\n",
    "ENHANCED_TRANSACTION_PENALTY = 0.00001  # REDUCED: 80% lower than original\n",
    "\n",
    "# REBALANCED REWARD SCALES  \n",
    "ENHANCED_ACTION_REWARD_SCALE = 50.0   # INCREASED: 500x vs original (was 0.1)\n",
    "STATIC_POSITION_PENALTY = 10.0        # NEW: Penalty for not changing position\n",
    "ZONE_REWARD_MULTIPLIER = 25.0         # NEW: Extra multiplier for good zone actions\n",
    "MOMENTUM_REWARD_SCALE = 15.0           # NEW: Reward for trading with momentum\n",
    "\n",
    "print(f\"üìà ENHANCED PARAMETERS:\")\n",
    "print(f\"   Action Reward Scale: {ENHANCED_ACTION_REWARD_SCALE} (vs 0.1 original - 500x increase!)\")\n",
    "print(f\"   Static Penalty: {STATIC_POSITION_PENALTY} (NEW - penalize unchanging positions)\")\n",
    "print(f\"   Zone Multiplier: {ZONE_REWARD_MULTIPLIER} (NEW - extra rewards for good trades)\")\n",
    "print(f\"   Transaction Costs: {ENHANCED_FEE_RATE + ENHANCED_SLIPPAGE} (vs 0.0002 - 50% reduction)\")\n",
    "\n",
    "# ÂèØË∞ÉÁº©ÊîæÔºà‰Ω†‰πüÂèØ‰ª•ÊîæÂà∞ JSON ÈáåÔºâ\n",
    "PNL_REWARD_SCALE = 100.0      # Â∞Ü ŒîNAV / NAV ÂΩí‰∏ÄÂêéÊîæÂ§ß‰∏ÄÁÇπÔºå‰æø‰∫éÂ≠¶‰π†\n",
    "INCREMENT_STEP_SIZE = 0.5     # Âä®‰ΩúÊ≠•ÈïøÔºöaction‚àà[-1,1] -> ‰ªì‰ΩçÂ¢ûÈáè‚àà[-0.5,0.5]\n",
    "\n",
    "class EnhancedTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Enhanced Trading Environment - Incremental actions + PnL reward + zone-shaped incentives\n",
    "    - Âä®‰Ωú‰∏∫‚ÄúÂ¢ûÈáèË∞É‰ªì‚Äù\n",
    "    - Âç≥Êó∂Â•ñÂä±‰ª•‚ÄúÂáÄÂÄºÂèòÂåñÔºàÂê´‰∫§ÊòìÊàêÊú¨Ôºâ‚Äù‰∏∫‰∏ª + ÂΩ¢Áä∂Â•ñÂä±\n",
    "    - CLOSE/NEUTRAL Âå∫ÊøÄÂä±‰øÆÊ≠£ÔºåÈÅøÂÖç‚ÄúÂºÄ‰ªìË¢´ÂäùÈÄÄ‚ÄùÂíå‚ÄúÂ•ñÂä±Â∞èÂä®‰Ωú‚Äù\n",
    "    - zone ÂΩí‰∏ÄÂåñËøõÂÖ•ËßÇÊµã\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, feat_cols, episode_length: int = 1000, randomize_start: bool = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df.copy()\n",
    "        self.feat_cols = feat_cols\n",
    "        self.episode_length = int(episode_length)\n",
    "        self.randomize_start = bool(randomize_start)\n",
    "\n",
    "        # Âü∫Á°ÄÊï∞ÁªÑ\n",
    "        self.prices = self.df[PRICE_COL].astype(float).values\n",
    "        self.z_scores = self.df['z_score'].astype(float).values\n",
    "        self.zones = self.df['zone'].astype(int).values\n",
    "\n",
    "        # Ëµ∑Ê≠¢ËæπÁïåÔºàÂÅ•Â£ÆÊÄßÔºâ\n",
    "        self.min_start = int(max(MA_PERIOD, WINDOW_SIZE))\n",
    "        self.max_start = int(len(self.df) - self.episode_length - 2)\n",
    "        if self.max_start < self.min_start:\n",
    "            self.episode_length = max(10, len(self.df) - self.min_start - 2)\n",
    "            self.max_start = max(self.min_start, len(self.df) - self.episode_length - 2)\n",
    "            self.randomize_start = False\n",
    "            print(f\"      ‚ö†Ô∏è Data short. Adjusted episode_length={self.episode_length}, randomize_start=False\")\n",
    "\n",
    "        # Âä®‰ΩúÔºö[-1,1] Ë∞É‰ªìÊåá‰ª§ÔºàÂ¢ûÈáèÔºâ\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        # ËßÇÊµãÔºö‰øùÊåÅ 6 Áª¥ÔºàÁî® zone_norm Êõø‰ª£ÂéüÂßã zoneÔºâ\n",
    "        # [position, z_score, zone_norm, price_mom, z_mom, position_change]\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([-1.0, -5.0, -1.0, -0.1, -2.0, -1.0], dtype=np.float32),\n",
    "            high=np.array([ 1.0,  5.0,  1.0,  0.1,  2.0,  1.0], dtype=np.float32),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Áä∂ÊÄÅ\n",
    "        self.position_history = []\n",
    "        self.static_steps = 0\n",
    "\n",
    "        self.current_step = None\n",
    "        self.episode_start = None\n",
    "        self.position = None\n",
    "        self.portfolio_value = None\n",
    "        self.cash = None\n",
    "        self.shares = None\n",
    "\n",
    "        # ‚Äî‚Äî ÂèØË∞ÉÂ±ûÊÄßÔºà‰∏é‰Ω†ÁöÑÊâπÈáèËÆ≠ÁªÉÂ≠êÁ±ª‰∏ÄËá¥Ôºâ‚Äî‚Äî\n",
    "        self.action_reward_scale    = ENHANCED_ACTION_REWARD_SCALE\n",
    "        self.zone_reward_multiplier = ZONE_REWARD_MULTIPLIER\n",
    "        self.static_penalty_scale   = STATIC_POSITION_PENALTY\n",
    "        self.momentum_reward_scale  = MOMENTUM_REWARD_SCALE\n",
    "        self.static_delta_thresh    = 0.01\n",
    "\n",
    "        # ‚úÖ ÂÆû‰æãÁ∫ßÊ≠•Èïø & PnL Áº©ÊîæÔºàÊõø‰ª£ÂÖ®Â±Ä‰øÆÊîπÔºåÈÅøÂÖçË∑®Ê®°ÂûãÂâØ‰ΩúÁî®Ôºâ\n",
    "        self.increment_step_size = float(INCREMENT_STEP_SIZE)\n",
    "        self.pnl_reward_scale    = float(PNL_REWARD_SCALE)\n",
    "\n",
    "    # ------------------------ Observations ------------------------\n",
    "    def _get_observation(self) -> np.ndarray:\n",
    "        position = float(self.position)\n",
    "        z_score = float(self.z_scores[self.current_step])\n",
    "        zone = int(self.zones[self.current_step])\n",
    "        zone_norm = float((zone - 2.0) / 2.0)  # [-1,1]\n",
    "\n",
    "        price_momentum = 0.0\n",
    "        z_momentum = 0.0\n",
    "        position_change = 0.0\n",
    "\n",
    "        if self.current_step > 0:\n",
    "            prev_price = float(self.prices[self.current_step - 1])\n",
    "            cur_price  = float(self.prices[self.current_step])\n",
    "            if prev_price > 0:\n",
    "                price_momentum = (cur_price - prev_price) / prev_price\n",
    "                price_momentum = float(np.clip(price_momentum, -0.1, 0.1))\n",
    "\n",
    "            z_momentum = float(np.clip(self.z_scores[self.current_step] - self.z_scores[self.current_step - 1], -2.0, 2.0))\n",
    "\n",
    "            if self.position_history:\n",
    "                position_change = float(np.clip(position - self.position_history[-1], -1.0, 1.0))\n",
    "\n",
    "        return np.array([position, z_score, zone_norm, price_momentum, z_momentum, position_change], dtype=np.float32)\n",
    "\n",
    "    # ------------------------ Shaping Rewards (zone/momentum/static) ------------------------\n",
    "    def _shaping_rewards(self, action: float) -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        ËøîÂõû: (zone_shaping, static_penalty, momentum_reward)\n",
    "        - ‰∏çÂê´ PnLÔºõPnL Âú® step() ‰∏≠Áî® ŒîNAV ËÆ°ÁÆó\n",
    "        \"\"\"\n",
    "        current_zone = int(self.zones[self.current_step])\n",
    "        zone_shaping = 0.0\n",
    "\n",
    "        # LONG/SHORT Âå∫ÔºöÊñπÂêëÊ≠£Á°ÆÂ•ñÂä±Ôºà‰πò multiplierÔºâÔºåÊñπÂêëÈîôËØØËΩªÁΩö\n",
    "        if current_zone == TradingZone.LONG_ZONE.value:\n",
    "            # Ë∂äÂ§öÂÅöÂ§öË∂äÂ•ΩÔºõÂÅöÁ©∫ËΩªÁΩö\n",
    "            zone_shaping = self.action_reward_scale * (action if action > 0 else 0.5 * action) * self.zone_reward_multiplier\n",
    "\n",
    "        elif current_zone == TradingZone.SHORT_ZONE.value:\n",
    "            # Ë∂äÂ§öÂÅöÁ©∫Ë∂äÂ•ΩÔºõÂÅöÂ§öËΩªÁΩö\n",
    "            if action < 0:\n",
    "                zone_shaping = self.action_reward_scale * abs(action) * self.zone_reward_multiplier\n",
    "            else:\n",
    "                zone_shaping = -self.action_reward_scale * 0.5 * action\n",
    "\n",
    "        elif current_zone == TradingZone.CLOSE_ZONE.value:\n",
    "            # Â•ñÂä±‚ÄúÂáè‰ªìÂõû 0‚ÄùÔºåÂπ∂ÂØπÊåÅÊúâÈùûÈõ∂‰ªì‰ΩçËΩªÁΩöÔºõ‰ªé 0 ÂºÄ‰ªì‰∏çÂÜçË¢´ÂäùÈÄÄ\n",
    "            position_reduction = max(0.0, abs(self.position) - abs(self.position + self.increment_step_size * action))\n",
    "            zone_shaping = self.action_reward_scale * position_reduction * (self.zone_reward_multiplier / 25.0)\n",
    "            zone_shaping += -0.2 * self.action_reward_scale * abs(self.position)\n",
    "\n",
    "        elif current_zone in [TradingZone.NEUTRAL_LONG.value, TradingZone.NEUTRAL_SHORT.value]:\n",
    "            # ‰∏çÂ•ñÂä±‚ÄúÂ∞èÂä®‰Ωú‚ÄùÔºå‰ªÖËΩªÁΩöËøáÂ§ß‰ªì‰ΩçÔºàÈºìÂä±ËΩª‰ªìËßÇÊúõÔºâ\n",
    "            zone_shaping = -0.1 * self.action_reward_scale * max(0.0, abs(self.position) - 0.2)\n",
    "\n",
    "        # ÂèçÈùôÊ≠¢ÊÉ©ÁΩöÔºöÂä®‰Ωú‰∏éÂΩìÂâç‰ªì‰ΩçËøáËøëÊó∂ÈÄíÂ¢ûÊÉ©ÁΩö\n",
    "        static_penalty = 0.0\n",
    "        if abs(action) < self.static_delta_thresh:\n",
    "            self.static_steps += 1\n",
    "            static_penalty = -self.static_penalty_scale * (1.0 + 0.1 * self.static_steps)\n",
    "        else:\n",
    "            self.static_steps = 0\n",
    "\n",
    "        # Âä®ÈáèÂ•ñÂä±ÔºöÈ°∫ÂäøÂ∞èÂä†ÂàÜ\n",
    "        momentum_reward = 0.0\n",
    "        if self.current_step > 0:\n",
    "            prev_price = float(self.prices[self.current_step - 1])\n",
    "            cur_price  = float(self.prices[self.current_step])\n",
    "            if prev_price > 0:\n",
    "                pm = (cur_price - prev_price) / prev_price\n",
    "                if (action > 0 and pm > 0) or (action < 0 and pm < 0):\n",
    "                    momentum_reward = self.momentum_reward_scale * abs(action) * abs(pm)\n",
    "\n",
    "        return float(zone_shaping), float(static_penalty), float(momentum_reward)\n",
    "\n",
    "    # ------------------------ Portfolio update (incremental action) ------------------------\n",
    "    def _update_portfolio_incremental(self, action: float):\n",
    "        \"\"\"\n",
    "        Â∞Ü action ËßÜ‰∏∫‚ÄúË∞É‰ªìÂπÖÂ∫¶‚ÄùÔºåÂπ∂Âú®ÂΩìÂâçÊó∂ÂàªÊàê‰∫§ÔºåÊâ£ÁúüÂÆûÊàêÊú¨ÔºõÈöèÂêéÁî®‰∏ã‰∏ÄÊó∂Âàª‰ª∑Ê†ºÈáç‰º∞ÂáÄÂÄº„ÄÇ\n",
    "        \"\"\"\n",
    "        # ËÆ∞ÂΩïÂéÜÂè≤\n",
    "        self.position_history.append(self.position)\n",
    "        if len(self.position_history) > 10:\n",
    "            self.position_history.pop(0)\n",
    "\n",
    "        # ËÆ°ÁÆóÊñ∞ÁõÆÊ†á‰ªì‰ΩçÔºàÂ¢ûÈáèÔºâ\n",
    "        new_position = float(np.clip(self.position + self.increment_step_size * action, -1.0, 1.0))\n",
    "        position_change = new_position - self.position\n",
    "\n",
    "        cur_price = float(self.prices[self.current_step])\n",
    "        if cur_price <= 0:\n",
    "            cur_price = 1e-8\n",
    "\n",
    "        # ÊúâË∞É‰ªì -> Êâ£ÊàêÊú¨ -> Êõ¥Êñ∞ÊåÅ‰ªì\n",
    "        if abs(position_change) > 1e-6:\n",
    "            trade_value = abs(position_change) * self.portfolio_value\n",
    "            trade_cost  = trade_value * (ENHANCED_FEE_RATE + ENHANCED_SLIPPAGE)  # ÁúüÂÆûÊàêÊú¨‰ªÖÊâ£‰∏ÄÊ¨°\n",
    "\n",
    "            self.position = new_position\n",
    "            target_equity_value = self.position * self.portfolio_value\n",
    "            self.shares = target_equity_value / cur_price\n",
    "            self.cash   = self.portfolio_value - target_equity_value - trade_cost\n",
    "        else:\n",
    "            self.position = new_position  # ‰∏çÂèò\n",
    "\n",
    "        # Áî®‰∏ã‰∏ÄÊó∂Âàª‰ª∑Ê†ºÈáç‰º∞ÂáÄÂÄº\n",
    "        if self.current_step + 1 < len(self.prices):\n",
    "            next_price = float(self.prices[self.current_step + 1])\n",
    "            equity_value = self.shares * next_price\n",
    "            self.portfolio_value = float(self.cash + equity_value)\n",
    "\n",
    "    # ------------------------ Reset/Step ------------------------\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[Dict[str, Any]] = None) -> Tuple[np.ndarray, Dict]:\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        if self.randomize_start:\n",
    "            start_low = self.min_start\n",
    "            start_high = max(self.min_start + 1, self.max_start + 1)\n",
    "            self.episode_start = int(self.np_random.integers(start_low, start_high))\n",
    "        else:\n",
    "            self.episode_start = int(self.min_start)\n",
    "\n",
    "        self.current_step = int(self.episode_start)\n",
    "        self.position = 0.0\n",
    "        self.portfolio_value = float(ENHANCED_SEED_MONEY)\n",
    "        self.cash = float(ENHANCED_SEED_MONEY)\n",
    "        self.shares = 0.0\n",
    "\n",
    "        self.position_history = []\n",
    "        self.static_steps = 0\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = {\n",
    "            \"portfolio_value\": float(self.portfolio_value),\n",
    "            \"position\": float(self.position),\n",
    "            \"nav\": float(self.portfolio_value / ENHANCED_SEED_MONEY)\n",
    "        }\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, float, bool, bool, Dict]:\n",
    "        # ÂΩí‰∏ÄÂåñÂçïÂÄºÂä®‰Ωú\n",
    "        a = float(np.clip(action if np.isscalar(action) else action[0], -1.0, 1.0))\n",
    "\n",
    "        # episode ÁªìÊùüÊ£ÄÊü•\n",
    "        if self.current_step >= self.episode_start + self.episode_length:\n",
    "            observation = self._get_observation()\n",
    "            info = {\n",
    "                \"portfolio_value\": float(self.portfolio_value),\n",
    "                \"position\": float(self.position),\n",
    "                \"nav\": float(self.portfolio_value / ENHANCED_SEED_MONEY)\n",
    "            }\n",
    "            return observation, 0.0, True, False, info\n",
    "\n",
    "        # ÂΩ¢Áä∂Â•ñÂä±ÔºàÂü∫‰∫éÂΩìÂâçÊ≠•Áä∂ÊÄÅÔºâ\n",
    "        zone_shaping, static_penalty, momentum_reward = self._shaping_rewards(a)\n",
    "\n",
    "        # ËÆ∞ÂΩïÊóßÂáÄÂÄº -> Ë∞É‰ªìÂπ∂Èáç‰º∞ -> ËÆ°ÁÆó PnL Â•ñÂä±\n",
    "        old_value = float(self.portfolio_value)\n",
    "        self._update_portfolio_incremental(a)\n",
    "        pnl_reward = 0.0\n",
    "        if old_value > 0:\n",
    "            pnl_reward = (self.portfolio_value - old_value) / old_value * self.pnl_reward_scale\n",
    "\n",
    "        # ÂêàÊàêÂ•ñÂä±\n",
    "        total_reward = float(pnl_reward + zone_shaping + static_penalty + momentum_reward)\n",
    "\n",
    "        # Êé®ËøõÊó∂Èó¥\n",
    "        self.current_step += 1\n",
    "        terminated = bool(self.current_step >= self.episode_start + self.episode_length)\n",
    "        truncated = False\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = {\n",
    "            \"portfolio_value\": float(self.portfolio_value),\n",
    "            \"position\": float(self.position),\n",
    "            \"nav\": float(self.portfolio_value / ENHANCED_SEED_MONEY),\n",
    "            \"pnl_reward\": float(pnl_reward),\n",
    "            \"zone_shaping\": float(zone_shaping),\n",
    "            \"static_penalty\": float(static_penalty),\n",
    "            \"momentum_reward\": float(momentum_reward),\n",
    "            \"static_steps\": int(self.static_steps)\n",
    "        }\n",
    "        return observation, float(total_reward), terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14318f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== BATCH TRAINING SETUP - LOAD FROM CONFIG FILE =====================\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd  # ‚úÖ Ë°•Ôºö‰Ω†‰∏ãÈù¢Áî®Âà∞‰∫Ü pd\n",
    "\n",
    "print(\"\\nüéØ BATCH TRAINING SETUP - LOADING FROM CONFIG FILE\")\n",
    "print(\"=================================================\")\n",
    "print(\"üîÑ Loading training configurations from external JSON file\")\n",
    "\n",
    "# Load paper-based processed data\n",
    "if 'train_df' not in locals():\n",
    "    print(\"   üìÅ Loading paper-based data...\")\n",
    "    train_df = pd.read_csv(os.path.join(OUTPUT_DIR, \"train_paper.csv\"))\n",
    "    test_df = pd.read_csv(os.path.join(OUTPUT_DIR, \"test_paper.csv\"))\n",
    "    print(f\"      Train: {len(train_df)} rows, Test: {len(test_df)} rows\")\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\n   üîç Data validation:\")\n",
    "required_cols = [TS_COL, PRICE_COL, 'z_score', 'zone']\n",
    "for col in required_cols:\n",
    "    if col not in train_df.columns:\n",
    "        raise ValueError(f\"Missing required column: {col}\")\n",
    "    print(f\"      ‚úÖ {col}: range [{train_df[col].min():.3f}, {train_df[col].max():.3f}]\")\n",
    "\n",
    "# ===================== LOAD TRAINING CONFIGURATIONS FROM JSON =====================\n",
    "config_file = \"training_config.json\"\n",
    "\n",
    "def _with_defaults(p: dict) -> dict:\n",
    "    \"\"\"ÁªôÊØè‰∏™ÈÖçÁΩÆË°•ÈªòËÆ§ÂÄºÔºåÂÖºÂÆπÊñ∞ÁéØÂ¢ÉÁöÑÂèØË∞ÉÈ°π\"\"\"\n",
    "    p = dict(p or {})\n",
    "    # ÁéØÂ¢ÉÂèØË∞ÉÔºà‰∏é EnhancedTradingEnv ACTIVE ÁâàÊú¨‰∏ÄËá¥Ôºâ\n",
    "    p.setdefault('action_reward_scale', 50.0)\n",
    "    p.setdefault('zone_reward_multiplier', 25.0)\n",
    "    p.setdefault('static_penalty', 10.0)\n",
    "    p.setdefault('momentum_reward_scale', 15.0)\n",
    "    p.setdefault('static_delta_thresh', 0.01)\n",
    "    # ÔºàÂèØÈÄâÔºâÂÖ®Â±ÄÁº©Êîæ\n",
    "    p.setdefault('increment_step_size', None)  # None=Áî®ÁéØÂ¢ÉÈªòËÆ§\n",
    "    p.setdefault('pnl_reward_scale', None)     # None=Áî®ÁéØÂ¢ÉÈªòËÆ§\n",
    "    # ÁÆóÊ≥ïË∂ÖÂèÇ\n",
    "    p.setdefault('learning_rate', 5e-4)\n",
    "    p.setdefault('n_steps', 1024)\n",
    "    p.setdefault('gamma', 0.99)\n",
    "    p.setdefault('gae_lambda', 0.95)\n",
    "    p.setdefault('ent_coef', 0.02)\n",
    "    p.setdefault('vf_coef', 0.5)\n",
    "    p.setdefault('max_grad_norm', 0.5)\n",
    "    p.setdefault('total_timesteps', 75000)\n",
    "    return p\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüìÑ Loading configurations from: {config_file}\")\n",
    "    with open(config_file, 'r') as f:\n",
    "        raw = json.load(f)\n",
    "    # ÂÖºÂÆπ‰∏§ÁßçÁªìÊûÑÔºö{\"training_configurations\":[...]} Êàñ Áõ¥Êé•ÊòØ list\n",
    "    training_configs = raw.get('training_configurations', raw)\n",
    "    if not isinstance(training_configs, list):\n",
    "        raise ValueError(\"training_configurations should be a list of configs\")\n",
    "    # Ë°•ÈªòËÆ§ÂÄº\n",
    "    for cfg in training_configs:\n",
    "        cfg.setdefault('name', 'unnamed_config')\n",
    "        cfg.setdefault('description', '')\n",
    "        cfg['params'] = _with_defaults(cfg.get('params', {}))\n",
    "    print(f\"   ‚úÖ Successfully loaded {len(training_configs)} configurations\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"   ‚ùå Config file '{config_file}' not found!\")\n",
    "    print(f\"   üí° Using fallback minimal configuration...\")\n",
    "    training_configs = [\n",
    "        {\n",
    "            'name': 'fallback_config',\n",
    "            'description': 'Minimal fallback configuration',\n",
    "            'params': _with_defaults({\n",
    "                'action_reward_scale': 50.0,\n",
    "                'zone_reward_multiplier': 25.0,\n",
    "                'static_penalty': 10.0,\n",
    "                'learning_rate': 0.0005,\n",
    "                'total_timesteps': 50000\n",
    "            })\n",
    "        }\n",
    "    ]\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"   ‚ùå Error parsing JSON file: {str(e)}\")\n",
    "    print(f\"   üí° Please check the JSON syntax in {config_file}\")\n",
    "    raise\n",
    "\n",
    "# ===================== DISPLAY LOADED CONFIGS (SUMMARY) =====================\n",
    "print(\"\\nüßæ CONFIG SUMMARY\")\n",
    "print(\"-------------------------------------------------\")\n",
    "print(f\"Total configs loaded: {len(training_configs)}\")\n",
    "preview_n = min(5, len(training_configs))\n",
    "if preview_n:\n",
    "    print(f\"\\nüîé Preview first {preview_n}:\")\n",
    "    for i, cfg in enumerate(training_configs[:preview_n], start=1):\n",
    "        p = cfg['params']\n",
    "        print(f\"  {i}. {cfg['name']}\")\n",
    "        print(f\"     - desc: {cfg.get('description','')}\")\n",
    "        print(f\"     - env: action_reward_scale={p['action_reward_scale']}, \"\n",
    "              f\"zone_reward_multiplier={p['zone_reward_multiplier']}, \"\n",
    "              f\"static_penalty={p['static_penalty']}, \"\n",
    "              f\"momentum_reward_scale={p['momentum_reward_scale']}, \"\n",
    "              f\"static_delta_thresh={p['static_delta_thresh']}, \"\n",
    "              f\"increment_step_size={p.get('increment_step_size','default')}, \"\n",
    "              f\"pnl_reward_scale={p.get('pnl_reward_scale','default')}\")\n",
    "        print(f\"     - a2c: lr={p['learning_rate']}, n_steps={p['n_steps']}, \"\n",
    "              f\"gamma={p['gamma']}, gae_lambda={p['gae_lambda']}, \"\n",
    "              f\"ent_coef={p['ent_coef']}, vf_coef={p['vf_coef']}, \"\n",
    "              f\"max_grad_norm={p['max_grad_norm']}, total_timesteps={p['total_timesteps']}\")\n",
    "\n",
    "# ÂèØÈÄâÔºöÊääÊ∏ÖÂçïÂÜôÂà∞‰∏Ä‰∏™Â∞èÁöÑÂø´ÁÖßÊñá‰ª∂Ôºå‰æø‰∫éÂ§çÁõò\n",
    "snapshot_path = f\"training_config_snapshot_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(snapshot_path, \"w\") as f:\n",
    "    json.dump(training_configs, f, indent=2)\n",
    "print(f\"\\nüíæ Snapshot saved to: {snapshot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7610d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "# ===================== EXECUTE BATCH TRAINING WITH CHECKPOINT SUPPORT =====================\n",
    "print(\"\\nüî• STARTING BATCH TRAINING - ALL CONFIGURATIONS\")\n",
    "print(\"===============================================\")\n",
    "print(\"üîÑ Checkpoint support: Will skip existing models\")\n",
    "\n",
    "trained_models = {}\n",
    "training_results = []\n",
    "total_start_time = time.time()\n",
    "\n",
    "# Check for existing models and training summary\n",
    "existing_models = set()\n",
    "existing_summary_file = None\n",
    "\n",
    "# Find most recent training summary\n",
    "summary_files = glob.glob(\"batch_training_summary_*.json\")\n",
    "if summary_files:\n",
    "    existing_summary_file = max(summary_files)\n",
    "    print(f\"üìÅ Found existing training summary: {existing_summary_file}\")\n",
    "    \n",
    "    try:\n",
    "        with open(existing_summary_file, 'r') as f:\n",
    "            existing_results = json.load(f)\n",
    "        \n",
    "        # Load existing successful models\n",
    "        for result in existing_results:\n",
    "            if result.get('status') == 'success':\n",
    "                existing_models.add(result['name'])\n",
    "                training_results.append(result)  # Keep existing results\n",
    "        \n",
    "        print(f\"‚úÖ Found {len(existing_models)} existing successful models\")\n",
    "        print(f\"üîÑ Will resume training from where it left off\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not load existing summary: {str(e)}\")\n",
    "        print(f\"üîÑ Starting fresh training\")\n",
    "\n",
    "# Check for existing model files\n",
    "existing_model_files = set()\n",
    "for config in training_configs:\n",
    "    model_path = f\"./a2c_{config['name']}\"\n",
    "    if os.path.exists(f\"{model_path}.zip\"):\n",
    "        existing_model_files.add(config['name'])\n",
    "\n",
    "if existing_model_files:\n",
    "    print(f\"üìÇ Found {len(existing_model_files)} existing model files\")\n",
    "    print(f\"üîÑ These will be skipped even if not in summary\")\n",
    "\n",
    "# Calculate what needs to be trained\n",
    "configs_to_train = []\n",
    "skipped_configs = []\n",
    "\n",
    "for config in training_configs:\n",
    "    config_name = config['name']\n",
    "    \n",
    "    # Skip if model exists in summary or as file\n",
    "    if config_name in existing_models or config_name in existing_model_files:\n",
    "        skipped_configs.append(config_name)\n",
    "        \n",
    "        # Add to training results if not already there\n",
    "        if config_name not in [r['name'] for r in training_results]:\n",
    "            training_results.append({\n",
    "                'name': config_name,\n",
    "                'params': config['params'],\n",
    "                'model_path': f\"./a2c_{config_name}\",\n",
    "                'training_time_minutes': 0.0,  # Unknown time\n",
    "                'status': 'success',\n",
    "                'note': 'Loaded from existing model file'\n",
    "            })\n",
    "    else:\n",
    "        configs_to_train.append(config)\n",
    "\n",
    "print(f\"\\nüìä TRAINING PLAN:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total configurations: {len(training_configs)}\")\n",
    "print(f\"Already completed: {len(skipped_configs)}\")\n",
    "print(f\"Need to train: {len(configs_to_train)}\")\n",
    "print(f\"Estimated time: ~{len(configs_to_train) * 0.15:.1f} minutes\")\n",
    "\n",
    "if skipped_configs:\n",
    "    print(f\"\\n‚è≠Ô∏è  SKIPPING EXISTING MODELS:\")\n",
    "    for name in skipped_configs[:10]:  # Show first 10\n",
    "        print(f\"   ‚úÖ {name}\")\n",
    "    if len(skipped_configs) > 10:\n",
    "        print(f\"   ... and {len(skipped_configs) - 10} more\")\n",
    "\n",
    "if not configs_to_train:\n",
    "    print(f\"\\nüéâ ALL MODELS ALREADY TRAINED!\")\n",
    "    print(f\"‚úÖ No new training needed\")\n",
    "    successful_models = [r for r in training_results if r.get('status') == 'success']\n",
    "else:\n",
    "    print(f\"\\nüöÄ STARTING TRAINING FOR {len(configs_to_train)} NEW CONFIGURATIONS...\")\n",
    "\n",
    "# -------------------- ‰øÆÊîπÁÇπ ‚ë†ÔºöÂè™ÂÅöÂèÇÊï∞Ê≥®ÂÖ•Ôºå‰∏çÈáçÂÜôÂ•ñÂä± --------------------\n",
    "class ConfiguredEnhancedTradingEnv(EnhancedTradingEnv):\n",
    "    def __init__(self, df, feat_cols, episode_length=800, randomize_start=True, params=None):\n",
    "        super().__init__(df, feat_cols, episode_length, randomize_start)\n",
    "        p = params or {}\n",
    "        # ‚Äî‚Äî Êää JSON ÂèÇÊï∞ÁÅåËøõÁà∂Á±ªÁöÑÂèØË∞ÉÂ±ûÊÄßÔºàstep() ‰ºöËØªÂèñÂÆÉ‰ª¨Ôºâ‚Äî‚Äî\n",
    "        self.action_reward_scale    = float(p.get('action_reward_scale',    50.0))\n",
    "        self.zone_reward_multiplier = float(p.get('zone_reward_multiplier', 25.0))\n",
    "        self.static_penalty_scale   = float(p.get('static_penalty',         10.0))\n",
    "        self.momentum_reward_scale  = float(p.get('momentum_reward_scale',  15.0))\n",
    "        self.static_delta_thresh    = float(p.get('static_delta_thresh',    0.01))\n",
    "        # ‚úÖ ÂÆû‰æãÁ∫ßÊ≥®ÂÖ•ÔºöÊõø‰ª£ global Ë¶ÜÁõñÔºåÈÅøÂÖçË∑®Ê®°ÂûãÂâØ‰ΩúÁî®\n",
    "        if p.get('increment_step_size') is not None:\n",
    "            self.increment_step_size = float(p['increment_step_size'])\n",
    "        if p.get('pnl_reward_scale') is not None:\n",
    "            self.pnl_reward_scale = float(p['pnl_reward_scale'])\n",
    "\n",
    "# Train only the missing configurations\n",
    "for i, config in enumerate(configs_to_train):\n",
    "    config_name = config['name']\n",
    "    params = config['params']\n",
    "    \n",
    "    print(f\"\\nüéØ TRAINING CONFIG {i+1}/{len(configs_to_train)}: {config_name.upper()}\")\n",
    "    print(f\"   üìç Overall progress: {len(skipped_configs) + i + 1}/{len(training_configs)}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # -------------------- ‰øÆÊîπÁÇπ ‚ë°ÔºöÂàõÂª∫ env Êó∂Êää params ‰º†ËøõÂéª --------------------\n",
    "        def make_env():\n",
    "            env = ConfiguredEnhancedTradingEnv(\n",
    "                df=train_df,\n",
    "                feat_cols=feat_cols_paper,\n",
    "                episode_length=800,\n",
    "                randomize_start=True,\n",
    "                params=params\n",
    "            )\n",
    "            return Monitor(env)\n",
    "\n",
    "        train_env = DummyVecEnv([make_env])\n",
    "        \n",
    "        print(f\"   üîß Environment configured with custom parameters:\")\n",
    "        print(f\"      Action reward scale: {params.get('action_reward_scale', 50.0)}\")\n",
    "        print(f\"      Zone reward multiplier: {params.get('zone_reward_multiplier', 25.0)}\")\n",
    "        print(f\"      Static penalty: {params.get('static_penalty', 10.0)}\")\n",
    "        print(f\"      Momentum reward scale: {params.get('momentum_reward_scale', 15.0)}\")\n",
    "        if 'increment_step_size' in params or 'pnl_reward_scale' in params:\n",
    "            print(f\"      step_size={params.get('increment_step_size', 'default')}, \"\n",
    "                  f\"pnl_scale={params.get('pnl_reward_scale', 'default')}\")\n",
    "\n",
    "        # Create A2C model\n",
    "        model = A2C(\n",
    "            policy=\"MlpPolicy\",\n",
    "            env=train_env,\n",
    "            learning_rate=params.get('learning_rate', 0.0005),\n",
    "            n_steps=params.get('n_steps', 1024),\n",
    "            gamma=params.get('gamma', 0.99),\n",
    "            gae_lambda=params.get('gae_lambda', 0.95),\n",
    "            ent_coef=params.get('ent_coef', 0.02),\n",
    "            vf_coef=params.get('vf_coef', 0.5),\n",
    "            max_grad_norm=params.get('max_grad_norm', 0.5),\n",
    "            verbose=0,\n",
    "            seed=42,\n",
    "            device='auto'\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        total_timesteps = int(params.get('total_timesteps', 75000))\n",
    "        print(f\"   ‚è±Ô∏è  Training for {total_timesteps:,} timesteps...\")\n",
    "        model.learn(total_timesteps=total_timesteps)\n",
    "        \n",
    "        # Save the model\n",
    "        model_path = f\"./a2c_{config_name}\"\n",
    "        model.save(model_path)\n",
    "        trained_models[config_name] = model\n",
    "        \n",
    "        training_time = (time.time() - start_time) / 60.0\n",
    "        \n",
    "        print(f\"   ‚úÖ Training complete! Time: {training_time:.1f} minutes\")\n",
    "        print(f\"   üíæ Model saved to: {model_path}\")\n",
    "        \n",
    "        # Store results\n",
    "        training_results.append({\n",
    "            'name': config_name,\n",
    "            'params': params,\n",
    "            'model_path': model_path,\n",
    "            'training_time_minutes': training_time,\n",
    "            'status': 'success'\n",
    "        })\n",
    "        \n",
    "        # Save progress after each successful model (checkpoint)\n",
    "        checkpoint_file = f\"batch_training_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=2)\n",
    "        \n",
    "        print(f\"   üíæ Progress saved to: {checkpoint_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_time = (time.time() - start_time) / 60.0\n",
    "        print(f\"   ‚ùå Training failed: {str(e)}\")\n",
    "        print(f\"   ‚è±Ô∏è  Time before failure: {error_time:.1f} minutes\")\n",
    "        \n",
    "        training_results.append({\n",
    "            'name': config_name,\n",
    "            'params': params,\n",
    "            'error': str(e),\n",
    "            'training_time_minutes': error_time,\n",
    "            'status': 'failed'\n",
    "        })\n",
    "        \n",
    "        # Save progress even after failures\n",
    "        checkpoint_file = f\"batch_training_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
    "        with open(checkpoint_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=2)\n",
    "\n",
    "total_time = (time.time() - total_start_time) / 60.0\n",
    "successful_models = [r for r in training_results if r.get('status') == 'success']\n",
    "failed_models = [r for r in training_results if r.get('status') == 'failed']\n",
    "\n",
    "print(f\"\\nüéâ BATCH TRAINING COMPLETE!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚è±Ô∏è  Total time: {total_time:.1f} minutes\")\n",
    "print(f\"‚úÖ Successful models: {len(successful_models)}/{len(training_configs)}\")\n",
    "print(f\"‚ùå Failed models: {len(failed_models)}\")\n",
    "print(f\"‚è≠Ô∏è  Skipped existing: {len(skipped_configs)}\")\n",
    "print(f\"üÜï New models trained: {len(configs_to_train)}\")\n",
    "print(f\"üìÅ Models saved in current directory\")\n",
    "\n",
    "# Save final training summary\n",
    "final_summary_file = f\"batch_training_summary_{datetime.now().strftime('%Y%m%d_%H%M')}.json\"\n",
    "with open(final_summary_file, 'w') as f:\n",
    "    json.dump(training_results, f, indent=2)\n",
    "\n",
    "print(f\"üíæ Final training summary saved to: {final_summary_file}\")\n",
    "\n",
    "if successful_models:\n",
    "    print(f\"\\nüöÄ READY FOR EVALUATION OF ALL MODELS!\")\n",
    "    print(f\"üìä {len(successful_models)} models available for evaluation\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No successful models to evaluate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ef5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Áî®ËÆ≠ÁªÉÊó∂ÁöÑ params ËøòÂéüËØÑ‰º∞ÁéØÂ¢ÉÔºà‰∏éËÆ≠ÁªÉ‰øùÊåÅ‰∏ÄËá¥Ôºâ ===\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "def build_eval_env_from_params(params, df, feat_cols, episode_length=None, randomize_start=False):\n",
    "    ep_len = episode_length or max(100, len(df) - max(MA_PERIOD, WINDOW_SIZE) - 1)\n",
    "    p = params or {}\n",
    "\n",
    "    class EvalConfiguredEnv(EnhancedTradingEnv):\n",
    "        def __init__(self):\n",
    "            super().__init__(\n",
    "                df=df,\n",
    "                feat_cols=feat_cols,\n",
    "                episode_length=ep_len,\n",
    "                randomize_start=randomize_start\n",
    "            )\n",
    "            # ‚Äî‚Äî ‰∏éËÆ≠ÁªÉ‰∏ÄËá¥ÔºöÂè™Ê≥®ÂÖ•ÂèØË∞ÉÂ±ûÊÄßÔºàÁà∂Á±ª step() ‰ºöËØªÂèñÔºâ‚Äî‚Äî\n",
    "            self.action_reward_scale    = float(p.get('action_reward_scale',    50.0))\n",
    "            self.zone_reward_multiplier = float(p.get('zone_reward_multiplier', 25.0))\n",
    "            self.static_penalty_scale   = float(p.get('static_penalty',         10.0))\n",
    "            self.momentum_reward_scale  = float(p.get('momentum_reward_scale',  15.0))\n",
    "            self.static_delta_thresh    = float(p.get('static_delta_thresh',    0.01))\n",
    "\n",
    "            # ‚úÖ ÂÆû‰æãÁ∫ßÊ≥®ÂÖ•ÔºöÂä®‰ΩúÊ≠•Èïø & PnL Â•ñÂä±Áº©ÊîæÔºà‰∏çÂÜç‰øÆÊîπÂÖ®Â±ÄÔºåÈÅøÂÖçË∑®Ê®°ÂûãÂâØ‰ΩúÁî®Ôºâ\n",
    "            if p.get('increment_step_size') is not None:\n",
    "                self.increment_step_size = float(p['increment_step_size'])\n",
    "            if p.get('pnl_reward_scale') is not None:\n",
    "                self.pnl_reward_scale = float(p['pnl_reward_scale'])\n",
    "\n",
    "    # ÂåÖ‰∏ÄÂ±Ç Monitor Êñπ‰æøËÆ∞ÂΩïËØÑ‰º∞ÊåáÊ†áÔºàÂèØÈÄâÔºâ\n",
    "    return DummyVecEnv([lambda: Monitor(EvalConfiguredEnv())])\n",
    "\n",
    "def restore_model_and_env(model_entry, df, feat_cols):\n",
    "    \"\"\"\n",
    "    ÁªôÂÆö‰∏ÄÊù° training_results ËÆ∞ÂΩïÔºàÂê´ params„ÄÅmodel_pathÔºâÔºå\n",
    "    ÊÅ¢Â§çÔºöËØÑ‰º∞ÁéØÂ¢ÉÔºà‰∏éËÆ≠ÁªÉ‰∏ÄËá¥Ôºâ+ Â∑≤ËÆ≠ÁªÉÊ®°Âûã\n",
    "    \"\"\"\n",
    "    params = model_entry.get(\"params\", {})\n",
    "    model_path = model_entry[\"model_path\"]\n",
    "    env = build_eval_env_from_params(params, df=df, feat_cols=feat_cols, randomize_start=False)\n",
    "    model = A2C.load(model_path, device='auto')\n",
    "    return model, env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Paper-Based Evaluation and Visualization (FIXED) =====================\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\nüìä PAPER-BASED MODEL EVALUATION\")\n",
    "print(\"==============================\")\n",
    "print(\"This will capture all trading steps like the original but with paper-based methodology\")\n",
    "\n",
    "def evaluate_detailed_trading(model, env, num_episodes=1, evalulation_in_minutes=40320):\n",
    "    import numpy as np\n",
    "    print(f\"üìà Running detailed trading analysis...\")\n",
    "\n",
    "    def _unwrap_base_env(vecenv):\n",
    "        # ‚úÖ ‰øÆÂ§çÔºöÊ≠£Á°Æ‚ÄúÂâ•ÂåÖ‚ÄùÂà∞Â∫ïÂ±Ç envÔºàÂÖàÁî® unwrappedÔºåÂÜçÊ≤ø .env Èìæ‰∏ãÈíªÔºâ\n",
    "        base_env = vecenv.envs[0]\n",
    "        base_env = getattr(base_env, \"unwrapped\", base_env)\n",
    "        while hasattr(base_env, \"env\") and getattr(base_env, \"env\") is not None:\n",
    "            base_env = base_env.env\n",
    "        return base_env\n",
    "\n",
    "    all_episodes = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        print(f\"   Episode {episode + 1}/{num_episodes}\")\n",
    "\n",
    "        obs = env.reset()  # VecEnv.reset() -> obs\n",
    "        done = False\n",
    "        step_count = 0\n",
    "\n",
    "        episode_data = {\n",
    "            'timestamps': [], 'prices': [], 'portfolio_values': [], 'positions': [],\n",
    "            'z_scores': [], 'zones': [], 'actions': [], 'rewards': [], 'navs': []\n",
    "        }\n",
    "\n",
    "        while not done and step_count < evalulation_in_minutes:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, rewards, dones, infos = env.step(action)\n",
    "\n",
    "            base_env = _unwrap_base_env(env)\n",
    "\n",
    "            r0 = float(rewards[0]) if np.ndim(rewards) else float(rewards)\n",
    "            info0 = infos[0] if isinstance(infos, (list, tuple)) else infos\n",
    "\n",
    "            # action -> Ê†áÈáè\n",
    "            try:\n",
    "                a0 = float(np.array(action).reshape(-1)[0])\n",
    "            except Exception:\n",
    "                a0 = float(action[0]) if isinstance(action, (list, tuple)) else float(action)\n",
    "\n",
    "            cur_step = int(getattr(base_env, \"current_step\", 0))\n",
    "            if cur_step < len(base_env.prices):\n",
    "                episode_data['timestamps'].append(cur_step)\n",
    "                episode_data['prices'].append(float(base_env.prices[cur_step]))\n",
    "                episode_data['portfolio_values'].append(float(info0['portfolio_value']))\n",
    "                episode_data['positions'].append(float(info0['position']))\n",
    "                episode_data['z_scores'].append(float(base_env.z_scores[cur_step]) if cur_step < len(base_env.z_scores) else 0.0)\n",
    "                episode_data['zones'].append(int(base_env.zones[cur_step]) if cur_step < len(base_env.zones) else 2)\n",
    "                episode_data['actions'].append(a0)\n",
    "                episode_data['rewards'].append(r0)\n",
    "                episode_data['navs'].append(float(info0['nav']))\n",
    "\n",
    "            step_count += 1\n",
    "            done = bool(dones[0]) if isinstance(dones, (list, tuple, np.ndarray)) else bool(dones)\n",
    "\n",
    "        all_episodes.append(episode_data)\n",
    "\n",
    "        base_cash = ENHANCED_SEED_MONEY\n",
    "        final_value = episode_data['portfolio_values'][-1] if episode_data['portfolio_values'] else base_cash\n",
    "        total_return = (final_value - base_cash) / base_cash\n",
    "        total_steps = len(episode_data['portfolio_values'])\n",
    "        print(f\"      Steps: {total_steps}, Final Value: ${final_value:,.2f}, Return: {total_return:.2%}\")\n",
    "\n",
    "    return all_episodes\n",
    "\n",
    "def create_enhanced_trading_plots(episode_data, tag=\"model\"):\n",
    "    \"\"\"\n",
    "    Create enhanced trading visualizations matching the enhanced A2C style\n",
    "    Shows portfolio value comparison, drawdown, positions, and ETH price.\n",
    "    'tag' will be embedded into title and filename to avoid overwriting.\n",
    "    \"\"\"\n",
    "    if not episode_data['timestamps']:\n",
    "        print(\"‚ùå No data to plot\")\n",
    "        return\n",
    "\n",
    "    # Áî® step indices ‰∏∫Ê®™ËΩ¥\n",
    "    time_steps = list(range(len(episode_data['timestamps'])))\n",
    "\n",
    "    # Buy & Hold Âü∫ÂáÜ\n",
    "    prices = np.array(episode_data['prices'], dtype=float)\n",
    "    initial_price = prices[0]\n",
    "    buy_hold_values = [ENHANCED_SEED_MONEY * (price / initial_price) for price in prices]\n",
    "\n",
    "    # ---- ÁîªÂõæ ----\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(16, 12))\n",
    "    fig.suptitle(f'Enhanced A2C Trading Model Performance - {tag}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # 1) ÁªÑÂêà‰ª∑ÂÄº vs B&H\n",
    "    ax1 = axes[0]\n",
    "    portfolio_values = episode_data['portfolio_values']\n",
    "    ax1.plot(time_steps, portfolio_values, label='Paper-Based A2C Model', linewidth=2)\n",
    "    ax1.plot(time_steps, buy_hold_values, label='Buy & Hold', linewidth=2)\n",
    "    ax1.axhline(y=ENHANCED_SEED_MONEY, linestyle='--', alpha=0.7, label='Initial Investment')\n",
    "    ax1.set_title('Portfolio Value Comparison')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2) ÂõûÊí§\n",
    "    ax2 = axes[1]\n",
    "    pv = np.array(portfolio_values, dtype=float)\n",
    "    peak = np.maximum.accumulate(pv)\n",
    "    drawdown_pct = (pv - peak) / peak * 100\n",
    "    max_dd = np.min(drawdown_pct)\n",
    "    ax2.fill_between(time_steps, drawdown_pct, 0, alpha=0.3)\n",
    "    ax2.plot(time_steps, drawdown_pct, linewidth=1)\n",
    "    ax2.set_title(f'Drawdown Analysis (Max: {max_dd:.1f}%)')\n",
    "    ax2.set_ylabel('Drawdown (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3) ‰ªì‰Ωç\n",
    "    ax3 = axes[2]\n",
    "    positions = episode_data['positions']\n",
    "    ax3.plot(time_steps, positions, linewidth=1.5, label=\"Position\")\n",
    "    ax3.axhline(y=0, linestyle='-', alpha=0.5)\n",
    "    ax3.axhline(y=1, linestyle='--', alpha=0.5, label='Max Long')\n",
    "    ax3.axhline(y=-1, linestyle='--', alpha=0.5, label='Max Short')\n",
    "    ax3.set_title('Position over Time')\n",
    "    ax3.set_ylabel('Position [-1, 1]')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4) ‰ª∑Ê†º\n",
    "    ax4 = axes[3]\n",
    "    ax4.plot(time_steps, prices, linewidth=1, alpha=0.8)\n",
    "    ax4.set_title('ETH Price Movement During Evaluation')\n",
    "    ax4.set_ylabel('ETH Price ($)')\n",
    "    ax4.set_xlabel('Time Steps')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # --- ÂîØ‰∏ÄÊñá‰ª∂ÂêçÔºöÂåÖÂê´Ê®°Âûã tag ---\n",
    "    safe_tag = \"\".join(ch if ch.isalnum() or ch in \"-_.\" else \"_\" for ch in str(tag))\n",
    "    out_dir = \"eval_charts\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f'paper_based_performance_{safe_tag}.png')\n",
    "\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"üìÅ Saved chart: {out_path}\")\n",
    "\n",
    "def calculate_detailed_metrics(episode_data):\n",
    "    \"\"\"Calculate comprehensive trading metrics like original drl.ipynb\"\"\"\n",
    "    if not episode_data['portfolio_values']:\n",
    "        return {\"error\": \"No data for metrics calculation\"}\n",
    "    \n",
    "    portfolio_values = np.array(episode_data['portfolio_values'], dtype=float)\n",
    "    positions = np.array(episode_data['positions'], dtype=float)\n",
    "\n",
    "    # Basic metrics\n",
    "    initial_value = ENHANCED_SEED_MONEY  # ‚úÖ ÂØπÈΩêÊñ∞ÁéØÂ¢É\n",
    "    final_value = float(portfolio_values[-1])\n",
    "    total_return = (final_value - initial_value) / initial_value\n",
    "\n",
    "    # Calculate trades (position changes > threshold)\n",
    "    position_changes = np.abs(np.diff(positions))\n",
    "    trades = int(np.sum(position_changes > 0.01))  # Threshold for significant trade\n",
    "\n",
    "    # Calculate win rateÔºàÈÄêÊ≠• NAV ÂèòÂåñÔºâ\n",
    "    returns = np.diff(portfolio_values) / portfolio_values[:-1]\n",
    "    wins = int(np.sum(returns > 0))\n",
    "    losses = int(np.sum(returns < 0))\n",
    "    win_rate = wins / (wins + losses) if (wins + losses) > 0 else 0.0\n",
    "\n",
    "    # Average win/loss\n",
    "    avg_win = float(np.mean(returns[returns > 0])) if np.any(returns > 0) else 0.0\n",
    "    avg_loss = float(np.mean(returns[returns < 0])) if np.any(returns < 0) else 0.0\n",
    "\n",
    "    # Sharpe ratioÔºàminute-level ÂÅáËÆæÔºö‰∏ÄÂπ¥ ~ 525600 ÂàÜÈíüÔºâ\n",
    "    if len(returns) > 1 and np.std(returns) > 0:\n",
    "        sharpe = float(np.mean(returns) / np.std(returns) * np.sqrt(525600))\n",
    "    else:\n",
    "        sharpe = 0.0\n",
    "\n",
    "    # Maximum drawdown\n",
    "    peak = np.maximum.accumulate(portfolio_values)\n",
    "    drawdown = (portfolio_values - peak) / peak\n",
    "    max_drawdown = float(np.min(drawdown))\n",
    "\n",
    "    # Average position\n",
    "    avg_position = float(np.mean(np.abs(positions)))\n",
    "\n",
    "    # CAGRÔºàÁü≠Ê†∑Êú¨‰ªÖ‰ΩúÂèÇËÄÉÔºâ\n",
    "    periods = len(portfolio_values)\n",
    "    cagr = float((final_value / initial_value) ** (525600 / periods) - 1) if periods > 0 else 0.0\n",
    "\n",
    "    metrics = {\n",
    "        \"FinalNAV\": final_value / initial_value,\n",
    "        \"FinalValue\": final_value,\n",
    "        \"TotalReturn\": total_return,\n",
    "        \"CAGR\": cagr,\n",
    "        \"Sharpe\": sharpe,\n",
    "        \"MaxDD\": abs(max_drawdown),\n",
    "        \"Trades\": trades,\n",
    "        \"WinRate\": win_rate,\n",
    "        \"AvgWin\": avg_win,\n",
    "        \"AvgLoss\": avg_loss,\n",
    "        \"AvgPos\": avg_position,\n",
    "        \"TotalSteps\": periods\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "print(\"‚úÖ Evaluation functions defined\")\n",
    "print(\"   - evaluate_detailed_trading(): Captures all trading steps\")\n",
    "print(\"   - create_enhanced_trading_plots(): Shows price, positions, portfolio\")\n",
    "print(\"   - calculate_detailed_metrics(): Comprehensive performance metrics\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d82f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== EVALUATE ALL TRAINED MODELS (FIXED) =====================\n",
    "print(\"\\nüéØ EVALUATING ALL TRAINED MODELS\")\n",
    "print(\"===============================\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ÈÄâÂèñÊúÄÊñ∞ÁöÑËÆ≠ÁªÉÊëòË¶ÅÔºà‰ºòÂÖàÂõ∫ÂÆöÊñá‰ª∂ÂêçÔºåÂÖ∂Ê¨°Êåâ‰øÆÊîπÊó∂Èó¥Ôºâ\n",
    "summary_files = []\n",
    "if os.path.exists(\"batch_training_summary.json\"):\n",
    "    summary_files.append(\"batch_training_summary.json\")\n",
    "summary_files += glob.glob(\"batch_training_summary_*.json\")\n",
    "\n",
    "if summary_files:\n",
    "    latest_summary = max(summary_files, key=os.path.getmtime)\n",
    "    print(f\"üìÅ Loading training results from: {latest_summary}\")\n",
    "    with open(latest_summary, 'r') as f:\n",
    "        training_results = json.load(f)\n",
    "    successful_models = [r for r in training_results if r.get('status') == 'success']\n",
    "else:\n",
    "    print(\"‚ùå No training summary found\")\n",
    "    successful_models = []\n",
    "\n",
    "print(f\"üìä Evaluating {len(successful_models)} successfully trained models\")\n",
    "\n",
    "all_evaluation_results = []\n",
    "\n",
    "for i, result in enumerate(successful_models):\n",
    "    config_name = result['name']\n",
    "    model_path = result['model_path']\n",
    "    print(f\"\\nüìà EVALUATING {i+1}/{len(successful_models)}: {config_name.upper()}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    try:\n",
    "        # ‚úÖ ÂÖ≥ÈîÆÔºöÊåâËØ•Ê®°ÂûãÁöÑ params ËøòÂéüÁéØÂ¢É + Âä†ËΩΩÊ®°Âûã\n",
    "        model, test_env = restore_model_and_env(result, df=test_df, feat_cols=feat_cols_paper)\n",
    "\n",
    "        # ËøêË°åËØ¶ÁªÜËØÑ‰º∞ÔºàÁ°Æ‰øù evaluate_detailed_trading ‰∏∫ FIXED ÁâàÔºâ\n",
    "        detailed_episodes = evaluate_detailed_trading(model, test_env, num_episodes=1)\n",
    "\n",
    "        if detailed_episodes and detailed_episodes[0].get('portfolio_values'):\n",
    "            episode_data = detailed_episodes[0]\n",
    "            detailed_metrics = calculate_detailed_metrics(episode_data)\n",
    "\n",
    "            # ÂÖàÁÆó avg_abs_positionÔºåÁõ¥Êé•Â≠òËøõÂéªÔºåÈÅøÂÖçÂêéÈù¢ÈáçÂ§çËÆ°ÁÆó\n",
    "            avg_pos = float(np.mean(np.abs(episode_data['positions']))) if episode_data.get('positions') else float('inf')\n",
    "\n",
    "            all_evaluation_results.append({\n",
    "                'config_name': config_name,\n",
    "                'model_path': model_path,\n",
    "                'metrics': detailed_metrics,\n",
    "                'episode_data': episode_data,\n",
    "                'avg_abs_position': avg_pos\n",
    "            })\n",
    "\n",
    "            print(f\"   üìä METRICS SUMMARY:\")\n",
    "            print(f\"      Final NAV: {detailed_metrics['FinalNAV']:.3f}\")\n",
    "            print(f\"      Avg |Position|: {avg_pos:.3f}\")\n",
    "            print(f\"      Trades: {detailed_metrics['Trades']}\")\n",
    "            print(f\"      Sharpe: {detailed_metrics['Sharpe']:.3f}\")\n",
    "\n",
    "            status = \"üü¢ BALANCED - Static position problem SOLVED!\" if avg_pos < 0.5 else \\\n",
    "                     (\"üü° MODERATE - Partially solved\" if avg_pos < 0.7 else \"üî¥ STATIC - Still has position sticking\")\n",
    "            print(f\"      Status: {status}\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Evaluation failed - no trading data\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Evaluation error: {e}\")\n",
    "\n",
    "# ÊØîËæÉÊ±áÊÄª\n",
    "print(f\"\\nüèÜ FINAL COMPARISON - ALL MODELS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<20} {'NAV':<8} {'AvgPos':<8} {'Trades':<8} {'Sharpe':<8} {'Status':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if all_evaluation_results:\n",
    "    for r in sorted(all_evaluation_results, key=lambda x: x['avg_abs_position']):\n",
    "        name = r['config_name'][:18]\n",
    "        nav = f\"{r['metrics']['FinalNAV']:.3f}\"\n",
    "        avg_pos = f\"{r['avg_abs_position']:.3f}\"\n",
    "        trades = str(r['metrics']['Trades'])\n",
    "        sharpe = f\"{r['metrics']['Sharpe']:.2f}\"\n",
    "        status = \"üü¢ BALANCED\" if r['avg_abs_position'] < 0.5 else (\"üü° MODERATE\" if r['avg_abs_position'] < 0.7 else \"üî¥ STATIC\")\n",
    "        print(f\"{name:<20} {nav:<8} {avg_pos:<8} {trades:<8} {sharpe:<8} {status:<15}\")\n",
    "else:\n",
    "    print(\"Ôºàno resultsÔºâ\")\n",
    "\n",
    "# ‰øùÂ≠òËØÑ‰º∞ÁªìÊûú\n",
    "eval_file = f\"batch_evaluation_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(eval_file, 'w') as f:\n",
    "    json.dump(all_evaluation_results, f, indent=2, default=str)\n",
    "print(f\"\\nüíæ Evaluation results saved to: {eval_file}\")\n",
    "\n",
    "# Êé®Ëçê & ÁîªÂõæÔºàÂ¶ÇÂ∑≤ÂÆö‰πâ create_enhanced_trading_plotsÔºâ\n",
    "if all_evaluation_results:\n",
    "    best_balanced = min(all_evaluation_results, key=lambda x: x['avg_abs_position'])\n",
    "    best_performance = max(all_evaluation_results, key=lambda x: x['metrics']['FinalNAV'])\n",
    "\n",
    "    print(f\"\\nüéØ RECOMMENDATIONS:\")\n",
    "    print(f\"   Most Balanced: {best_balanced['config_name']} \"\n",
    "          f\"(AvgPos: {best_balanced['avg_abs_position']:.3f}, NAV: {best_balanced['metrics']['FinalNAV']:.3f})\")\n",
    "    print(f\"   Best Performance: {best_performance['config_name']} \"\n",
    "          f\"(NAV: {best_performance['metrics']['FinalNAV']:.3f}, AvgPos: {best_performance['avg_abs_position']:.3f})\")\n",
    "\n",
    "    try:\n",
    "        plotted = set()\n",
    "        for chosen in [best_balanced, best_performance]:\n",
    "            cname = chosen['config_name']\n",
    "            if cname in plotted:\n",
    "                continue\n",
    "            create_enhanced_trading_plots(chosen['episode_data'], tag=cname)\n",
    "            plotted.add(cname)\n",
    "        print(f\"üìä Performance charts saved for {len(plotted)} model(s)\")\n",
    "    except NameError:\n",
    "        print(\"‚ÑπÔ∏è  Skipping plots (create_enhanced_trading_plots not defined)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No successful evaluations to analyze\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

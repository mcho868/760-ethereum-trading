{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f197fa237b29a1",
   "metadata": {},
   "source": [
    "Part 1: Data Preprocessing\n",
    "\n",
    "This part prepares the raw ETH/USDT 1-minute dataset for reinforcement learning. It sorts the data by timestamp, selects OHLCV and indicator features, creates additional features such as log returns, splits the dataset into training and testing sets, and standardizes all features to ensure stable training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0ff4a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: seaborn in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (6.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (1.7.1)\n",
      "Requirement already satisfied: stable-baselines3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: gymnasium in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (1.2.0)\n",
      "Requirement already satisfied: pyarrow in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (21.0.0)\n",
      "Requirement already satisfied: ta in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from plotly) (2.3.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from stable-baselines3) (2.8.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from stable-baselines3) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from gymnasium) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: filelock in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.19.1)\n",
      "Requirement already satisfied: setuptools in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from torch<3.0,>=2.3->stable-baselines3) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages (from jinja2->torch<3.0,>=2.3->stable-baselines3) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install numpy pandas matplotlib seaborn plotly scikit-learn stable-baselines3 gymnasium pyarrow ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198811f6940a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:09:25.487376Z",
     "start_time": "2025-09-04T10:08:14.172697Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/ETHUSDT_1m_with_indicators.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out.clip(\u001b[32m0.0\u001b[39m, \u001b[32m1.0\u001b[39m)\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# ===================== Load & clean / 读取与清洗 =====================\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m df = df.reset_index()                \u001b[38;5;66;03m# 防止 ts 在索引里 / in case ts was index\u001b[39;00m\n\u001b[32m     34\u001b[39m df.columns = df.columns.str.strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/ETHUSDT_1m_with_indicators.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===================== Config / 配置 =====================\n",
    "PATH = \"../ETHUSDT_1m_with_indicators.parquet\"\n",
    "TS_COL = \"ts\"                  # 时间戳列名 / timestamp column\n",
    "WIN = 60                       # 归一化滚动窗口 / rolling window (minutes)\n",
    "EPS = 1e-12                    # 防除零 / avoid division by zero\n",
    "OUTPUT_DIR = \"./processed_data_minmax\"\n",
    "\n",
    "# 列集合 / Column sets\n",
    "OHLCV = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "INDICATORS_PRICE_LEVEL = [\"BB_mid\",\"BB_high\",\"BB_low\",\"EMA_12\",\"EMA_26\"]  # 与价格同量纲的指标\n",
    "INDICATORS_OWN_SCALE  = [\"MACD\",\"MACD_signal\",\"MACD_diff\",\"ATR\"]          # 自身尺度的指标\n",
    "RSI_COL = \"RSI\"  # RSI 单独处理 / special-case for RSI (0..100)\n",
    "\n",
    "# ===================== Helpers / 工具函数 =====================\n",
    "def minmax_rolling(series: pd.Series, win: int, min_periods: int = 1) -> pd.Series:\n",
    "    \"\"\"滚动 min-max 归一化到 [0,1]；前期使用逐步扩大的窗口，避免 NaN\n",
    "    Rolling min-max to [0,1]; uses expanding window at the beginning to avoid NaNs.\n",
    "    \"\"\"\n",
    "    roll_min = series.rolling(win, min_periods=min_periods).min()\n",
    "    roll_max = series.rolling(win, min_periods=min_periods).max()\n",
    "    denom = (roll_max - roll_min).replace(0, np.nan)\n",
    "    out = (series - roll_min) / denom\n",
    "    # 处理 0 除与边界 / handle zero-division and bounds\n",
    "    out = out.fillna(0.5)   # 当区间无波动时给 0.5 中性值 / neutral when no range\n",
    "    return out.clip(0.0, 1.0)\n",
    "\n",
    "# ===================== Load & clean / 读取与清洗 =====================\n",
    "df = pd.read_parquet(PATH)\n",
    "df = df.reset_index()                # 防止 ts 在索引里 / in case ts was index\n",
    "df.columns = df.columns.str.strip()\n",
    "df = df.sort_values(TS_COL).reset_index(drop=True)\n",
    "\n",
    "# 检查必需列 / sanity check\n",
    "need = set([TS_COL] + OHLCV + [RSI_COL] + INDICATORS_PRICE_LEVEL + INDICATORS_OWN_SCALE)\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"[WARN] missing columns (will be ignored): {missing}\")\n",
    "\n",
    "# 仅保留存在的列名 / keep existing\n",
    "OHLCV = [c for c in OHLCV if c in df.columns]\n",
    "INDICATORS_PRICE_LEVEL = [c for c in INDICATORS_PRICE_LEVEL if c in df.columns]\n",
    "INDICATORS_OWN_SCALE = [c for c in INDICATORS_OWN_SCALE if c in df.columns]\n",
    "has_rsi = (RSI_COL in df.columns)\n",
    "\n",
    "# 替换无穷与异常 / replace infinities then keep NaNs for rolling minmax\n",
    "df[OHLCV + INDICATORS_PRICE_LEVEL + INDICATORS_OWN_SCALE + ([RSI_COL] if has_rsi else [])] = \\\n",
    "    df[OHLCV + INDICATORS_PRICE_LEVEL + INDICATORS_OWN_SCALE + ([RSI_COL] if has_rsi else [])] \\\n",
    "      .replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# ===================== Price-based normalization / 价格相关归一化 =====================\n",
    "# 价格用 60 分钟窗口的 low(min) 与 high(max) 做统一尺度 / use rolling low/high across last 60 mins\n",
    "roll_low  = df[\"low\"].rolling(WIN, min_periods=1).min()\n",
    "roll_high = df[\"high\"].rolling(WIN, min_periods=1).max()\n",
    "price_denom = (roll_high - roll_low).mask((roll_high - roll_low) == 0, EPS)\n",
    "\n",
    "# 保留原始列，同时新增 *_norm 列 / keep raw columns and add *_norm\n",
    "for col in [\"open\",\"high\",\"low\",\"close\"]:\n",
    "    if col in df.columns:\n",
    "        df[col + \"_norm\"] = ((df[col] - roll_low) / price_denom).clip(0.0, 1.0)\n",
    "\n",
    "# Volume：先对数再滚动归一化 / log1p then rolling min-max\n",
    "if \"volume\" in df.columns:\n",
    "    vol_log = np.log1p(df[\"volume\"].clip(lower=0))\n",
    "    df[\"volume_norm\"] = minmax_rolling(vol_log, WIN, min_periods=1)\n",
    "\n",
    "# ===================== Indicator normalization / 技术指标归一化 =====================\n",
    "# RSI：天然 0..100 → /100 到 [0,1]\n",
    "if has_rsi:\n",
    "    df[\"RSI_norm\"] = (df[\"RSI\"].clip(0, 100) / 100.0).fillna(0.5)\n",
    "\n",
    "# 与价格同量纲的指标，使用同一套 roll_low/roll_high\n",
    "for col in INDICATORS_PRICE_LEVEL:\n",
    "    df[col + \"_norm\"] = ((df[col] - roll_low) / price_denom).clip(0.0, 1.0)\n",
    "\n",
    "# 自有尺度的指标，用自身滚动 min-max\n",
    "for col in INDICATORS_OWN_SCALE:\n",
    "    df[col + \"_norm\"] = minmax_rolling(df[col], WIN, min_periods=1)\n",
    "\n",
    "# 额外：log return（可选）\n",
    "df[\"logret\"] = np.log(df[\"close\"]).diff()\n",
    "df[\"logret_norm\"] = minmax_rolling(df[\"logret\"].fillna(0), WIN, min_periods=1)\n",
    "\n",
    "\n",
    "# ===================== Split & export / 切分与导出 =====================\n",
    "#  按时间切分训练/测试 / Time-based split (80/20)\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df  = df.iloc[split_idx:].copy()\n",
    "train_df[\"split\"] = \"train\"\n",
    "test_df[\"split\"]  = \"test\"\n",
    "\n",
    "# 选择要导出的列：ts + 原始 OHLCV + 全部 *_norm 特征\n",
    "#    Select columns to export: ts + raw OHLCV + all *_norm features\n",
    "norm_cols = [c for c in df.columns if c.endswith(\"_norm\")]\n",
    "export_cols = [TS_COL] + OHLCV + norm_cols + [\"split\"]\n",
    "\n",
    "# 确认所有导出列都存在于两个子集 / Ensure all export columns exist in both splits\n",
    "missing_train = [c for c in export_cols if c not in train_df.columns]\n",
    "missing_test  = [c for c in export_cols if c not in test_df.columns]\n",
    "if missing_train or missing_test:\n",
    "    raise KeyError(f\"Export columns missing. \"\n",
    "                   f\"train_df missing: {missing_train}, test_df missing: {missing_test}\")\n",
    "\n",
    "# 对 *_norm 特征做 NaN/Inf 清洗并用中位数填充\n",
    "#    Clean NaN/Inf in *_norm features and fill with per-column median\n",
    "def fill_norm_with_median(df_sub, norm_feature_cols):\n",
    "    # 将 Inf 转为 NaN / replace Inf with NaN\n",
    "    df_sub.loc[:, norm_feature_cols] = df_sub[norm_feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    # 逐列用中位数填充；若整列都是 NaN，则回退为 0.5（中性值）\n",
    "    # Fill NaNs with column median; fallback to 0.5 if the column is all NaN\n",
    "    for col in norm_feature_cols:\n",
    "        med = df_sub[col].median()\n",
    "        if pd.isna(med):\n",
    "            med = 0.5\n",
    "        df_sub.loc[:, col] = df_sub[col].fillna(med)\n",
    "    return df_sub\n",
    "\n",
    "train_df = fill_norm_with_median(train_df, norm_cols)\n",
    "test_df  = fill_norm_with_median(test_df,  norm_cols)\n",
    "\n",
    "# 最终健检：确保没有 NaN/Inf 遗留 / Final sanity check: no NaN/Inf remaining\n",
    "assert np.isfinite(train_df[norm_cols].to_numpy()).all(), \"train_df still has NaN/Inf after fill.\"\n",
    "assert np.isfinite(test_df[norm_cols].to_numpy()).all(),  \"test_df still has NaN/Inf after fill.\"\n",
    "\n",
    "# 导出 CSV（仅导出所选列）/ Export CSVs (selected columns only)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(OUTPUT_DIR, \"train_minmax.csv\")\n",
    "test_path  = os.path.join(OUTPUT_DIR, \"test_minmax.csv\")\n",
    "combo_path = os.path.join(OUTPUT_DIR, \"combined_minmax.csv\")\n",
    "\n",
    "train_df[export_cols].to_csv(train_path, index=False, float_format=\"%.6f\")\n",
    "test_df[export_cols].to_csv(test_path,   index=False, float_format=\"%.6f\")\n",
    "pd.concat([train_df[export_cols], test_df[export_cols]], ignore_index=True)\\\n",
    "  .to_csv(combo_path, index=False, float_format=\"%.6f\")\n",
    "\n",
    "print(\"[OK] Exported CSVs with RAW OHLCV + *_norm features at\", OUTPUT_DIR)\n",
    "print(\"  -\", train_path)\n",
    "print(\"  -\", test_path)\n",
    "print(\"  -\", combo_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7e66994c2d7d",
   "metadata": {},
   "source": [
    "### Part 2: Environment Setup\n",
    "\n",
    "This part defines the custom trading environment `MinuteTradingEnv` based on the Gymnasium API. The environment simulates one-minute trading with continuous position control.\n",
    "\n",
    "- **Initialization**:\n",
    "  Load and clean the input data, define parameters such as window size, fees, slippage, and penalties. Set up action space as continuous positions in [-1, 1] and observation space as flattened windows of features.\n",
    "\n",
    "- **Observation**:\n",
    "  Construct state representations by extracting the most recent feature window and flattening it into a vector.\n",
    "\n",
    "- **Reset**:\n",
    "  Initialize the environment for a new episode with index at the end of the first window, flat position, and starting NAV = 1.\n",
    "\n",
    "- **Step Function**:\n",
    "  Execute one action, calculate log returns from consecutive prices, apply transaction costs and penalties, update NAV, and return the new observation, reward, termination flag, and info (including current NAV and position).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f36da7c5c5af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:39:27.176700Z",
     "start_time": "2025-09-04T10:39:27.157224Z"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "# 可选：如需类型提示，取消下一行注释\n",
    "# from typing import Dict, Optional, Tuple\n",
    "\n",
    "class MinuteTradingEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": []}\n",
    "\n",
    "    # ===== 1) 初始化 / Initialization =====\n",
    "    def __init__(self, df, feat_cols, window=60,\n",
    "                 fee_rate=0.0005, slippage=0.0002, pos_change_penalty=0.001,\n",
    "                 logret_clip=0.10, reward_clip=0.25, eps=1e-12,\n",
    "                 # ---- 止损与跟踪止盈参数 / Stop-loss & trailing-stop params ----\n",
    "                 open_thr=0.10,          # 视为“持仓”的阈值（|pos|>open_thr 才认为已开仓）\n",
    "                 flat_thr=0.05,          # 视为“空仓”的阈值（|pos|<=flat_thr 认为空仓）\n",
    "                 stop_loss_pct=0.02,     # 硬止损：相对开仓价的不利幅度（2%）\n",
    "                 trailing_stop_pct=0.03, # 跟踪止盈：相对开仓以来极值的回撤幅度（3%）\n",
    "                 # ---- 指标权重调整器 / Feature-weight controller ----\n",
    "                 feature_weights=None,   # 例: {\"RSI_norm\":1.5, \"MACD_norm\":0.8}\n",
    "                 normalize_weights=False,# 是否把权重按均值归一化，避免整体量级漂移\n",
    "                 weight_clip=(0.1, 5.0)  # 权重夹紧范围，防止极端放大/缩小\n",
    "                 ):\n",
    "        \"\"\"\n",
    "        Custom minute-level trading environment with risk controls (+ per-feature weights).\n",
    "        带风险控制（硬止损 + 跟踪止盈）与“指标权重调整器”的分钟级交易环境\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 数据清理 / Data cleaning\n",
    "        self.df = (df.replace([np.inf, -np.inf], np.nan)\n",
    "                     .dropna(subset=[\"close\"] + list(feat_cols))\n",
    "                     .reset_index(drop=True))\n",
    "        assert len(self.df) > window + 1, \"Data length must be larger than window size.\"\n",
    "\n",
    "        # 基础参数 / Basic settings\n",
    "        self.feat_cols = list(feat_cols)\n",
    "        self.window = window\n",
    "        self.fee_rate = fee_rate\n",
    "        self.slippage = slippage\n",
    "        self.pos_change_penalty = pos_change_penalty\n",
    "        self.logret_clip = logret_clip\n",
    "        self.reward_clip = reward_clip\n",
    "        self.eps = eps\n",
    "\n",
    "        # 风险控制参数 / Risk control params\n",
    "        self.open_thr = float(open_thr)\n",
    "        self.flat_thr = float(flat_thr)\n",
    "        self.stop_loss_pct = float(stop_loss_pct)\n",
    "        self.trailing_stop_pct = float(trailing_stop_pct)\n",
    "\n",
    "        # 缓存数据 / Cached arrays\n",
    "        self.prices = self.df[\"close\"].to_numpy(dtype=np.float64)\n",
    "        self.features = self.df[self.feat_cols].to_numpy(dtype=np.float32)\n",
    "\n",
    "        # === 指标权重：与 feat_cols 对齐的缩放向量 / per-feature scale vector ===\n",
    "        self._feat_index = {c: i for i, c in enumerate(self.feat_cols)}  # 列名->索引\n",
    "        self._feat_scale = np.ones(len(self.feat_cols), dtype=np.float32) # 默认全1\n",
    "        self._weight_clip = (float(weight_clip[0]), float(weight_clip[1]))\n",
    "        if feature_weights:\n",
    "            self._apply_feature_weights(feature_weights, normalize_weights)\n",
    "\n",
    "        # 动作与观测空间 / Action & Observation spaces\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf, high=np.inf,\n",
    "            shape=(self.window * len(self.feat_cols),),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # 时间控制 / Time indexing\n",
    "        self.start = self.window\n",
    "        self.end = len(self.df) - 2   # 预留 i+1 做结算\n",
    "        self.i = None\n",
    "        self.position = None\n",
    "        self.nav = None\n",
    "\n",
    "        # 进出场跟踪 / Entry tracking\n",
    "        self.entry_price = None   # 开仓参考价\n",
    "        self.entry_sign = 0       # 开仓方向（+1/-1）\n",
    "        self.peak_price = None    # 多头最高价（用于跟踪止盈）\n",
    "        self.trough_price = None  # 空头最低价（用于跟踪止盈）\n",
    "\n",
    "    # === 内部：应用权重 / Internal: apply feature weights ===\n",
    "    def _apply_feature_weights(self, weights, normalize: bool):\n",
    "        \"\"\"\n",
    "        根据传入的字典更新每列的缩放系数；可按均值归一化，避免整体量级变化。\n",
    "        Update per-feature scales from a dict; optionally normalize by mean.\n",
    "        \"\"\"\n",
    "        scale = self._feat_scale.copy()\n",
    "        lo, hi = self._weight_clip\n",
    "        for name, w in weights.items():\n",
    "            if name in self._feat_index:\n",
    "                scale[self._feat_index[name]] = np.clip(float(w), lo, hi)\n",
    "        if normalize:\n",
    "            m = float(np.mean(scale))\n",
    "            if m > 0:\n",
    "                scale = scale / m\n",
    "        self._feat_scale = scale.astype(np.float32)\n",
    "\n",
    "    # === 外部：运行时更新权重 / Public: update weights at runtime ===\n",
    "    def set_feature_weights(self, weights: dict, normalize: bool = False):\n",
    "        \"\"\"\n",
    "        训练/评估过程中随时更新部分或全部指标权重。\n",
    "        Update (a subset of) feature weights on the fly during training/evaluation.\n",
    "        \"\"\"\n",
    "        self._apply_feature_weights(weights, normalize)\n",
    "\n",
    "    # ===== 2) 构造观测 / Build observation =====\n",
    "    def _get_obs(self):\n",
    "        x = self.features[self.i - self.window + 1 : self.i + 1]  # [W, F]\n",
    "        # 按列加权 / per-feature scaling\n",
    "        x = x * self._feat_scale  # [W, F] * [F]（广播）\n",
    "        obs = x.reshape(-1).astype(np.float32)\n",
    "        assert np.isfinite(obs).all(), \"Observation contains NaN/Inf\"\n",
    "        return obs\n",
    "\n",
    "    # ===== 3) 重置环境 / Reset environment =====\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.i = self.start\n",
    "        self.position = 0.0\n",
    "        self.nav = 1.0\n",
    "\n",
    "        # 重置进出场跟踪 / reset entry trackers\n",
    "        self.entry_price = None\n",
    "        self.entry_sign = 0\n",
    "        self.peak_price = None\n",
    "        self.trough_price = None\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    # ===== 4) 执行一步（含止损逻辑）/ Take one step (with stops) =====\n",
    "    def step(self, action):\n",
    "        # --- 动作处理 / Action processing ---\n",
    "        a = float(np.clip(action[0], -1.0, 1.0))\n",
    "        prev_pos = self.position\n",
    "        self.position = a\n",
    "\n",
    "        # --- 价格获取 / Price handling ---\n",
    "        p_now  = float(self.prices[self.i])\n",
    "        p_next = float(self.prices[self.i + 1])\n",
    "        if not np.isfinite(p_now) or p_now <= 0:\n",
    "            p_now = max(1.0, p_next)\n",
    "        if not np.isfinite(p_next) or p_next <= 0:\n",
    "            p_next = p_now\n",
    "\n",
    "        # --- 对数收益 / Log return for i -> i+1 ---\n",
    "        ratio = max(p_next / max(p_now, self.eps), self.eps)\n",
    "        log_ret = float(np.log(ratio))\n",
    "        if self.logret_clip is not None:\n",
    "            log_ret = float(np.clip(log_ret, -self.logret_clip, self.logret_clip))\n",
    "\n",
    "        # ===== A) 开平仓事件跟踪 / Entry & tracking =====\n",
    "        # 进入“有效持仓”状态：|pos| > open_thr\n",
    "        became_long  = (abs(prev_pos) <= self.open_thr) and (self.position >  self.open_thr)\n",
    "        became_short = (abs(prev_pos) <= self.open_thr) and (self.position < -self.open_thr)\n",
    "        flattened    = (abs(prev_pos)  > self.open_thr) and (abs(self.position) <= self.flat_thr)\n",
    "\n",
    "        if flattened:\n",
    "            # 平仓 -> 清空跟踪器 / clear trackers on flatten\n",
    "            self.entry_price = None\n",
    "            self.entry_sign = 0\n",
    "            self.peak_price = None\n",
    "            self.trough_price = None\n",
    "\n",
    "        if became_long:\n",
    "            self.entry_price = p_now\n",
    "            self.entry_sign  = +1\n",
    "            self.peak_price  = p_now\n",
    "            self.trough_price = None\n",
    "\n",
    "        elif became_short:\n",
    "            self.entry_price = p_now\n",
    "            self.entry_sign  = -1\n",
    "            self.trough_price = p_now\n",
    "            self.peak_price   = None\n",
    "\n",
    "        # 若已持仓则更新极值（用于跟踪止盈）/ update extremes while in position\n",
    "        if self.entry_sign == +1:\n",
    "            self.peak_price = max(self.peak_price if self.peak_price is not None else p_now, p_now)\n",
    "        elif self.entry_sign == -1:\n",
    "            self.trough_price = min(self.trough_price if self.trough_price is not None else p_now, p_now)\n",
    "\n",
    "        # ===== B) 成本与惩罚 / Costs and penalties =====\n",
    "        pos_change = abs(self.position - prev_pos)\n",
    "        fee_slip = (self.fee_rate + self.slippage)\n",
    "        trade_cost = pos_change * fee_slip                     # 手续费 + 滑点\n",
    "        adj_penalty = self.pos_change_penalty * pos_change     # 调仓惩罚\n",
    "\n",
    "        # ===== C) 止损与跟踪止盈判定 / Stop-loss & trailing-stop checks =====\n",
    "        forced_flat = False\n",
    "        extra_close_cost = 0.0\n",
    "\n",
    "        if self.entry_sign != 0 and self.entry_price is not None:\n",
    "            # 硬止损（相对开仓价）\n",
    "            if self.entry_sign == +1:\n",
    "                hard_stop = (p_next <= self.entry_price * (1.0 - self.stop_loss_pct))\n",
    "            else:\n",
    "                hard_stop = (p_next >= self.entry_price * (1.0 + self.stop_loss_pct))\n",
    "\n",
    "            # 跟踪止盈（相对极值的回撤）\n",
    "            if self.entry_sign == +1 and self.peak_price is not None:\n",
    "                trail_stop = (p_next <= self.peak_price * (1.0 - self.trailing_stop_pct))\n",
    "            elif self.entry_sign == -1 and self.trough_price is not None:\n",
    "                trail_stop = (p_next >= self.trough_price * (1.0 + self.trailing_stop_pct))\n",
    "            else:\n",
    "                trail_stop = False\n",
    "\n",
    "            if hard_stop or trail_stop:\n",
    "                # 触发强制平仓：本步结束后把仓位设为 0，并加一次额外平仓成本\n",
    "                forced_flat = True\n",
    "                extra_close_cost = abs(self.position - 0.0) * fee_slip \\\n",
    "                                   + self.pos_change_penalty * abs(self.position - 0.0)\n",
    "\n",
    "        # ===== D) 单步收益与奖励 / Step return & reward =====\n",
    "        step_ret = self.position * log_ret - trade_cost - adj_penalty\n",
    "\n",
    "        # 若触发强制平仓，立刻扣一次额外成本（模拟被动平仓）/ apply extra cost if forced close\n",
    "        if forced_flat:\n",
    "            step_ret -= extra_close_cost\n",
    "\n",
    "        if self.reward_clip is not None:\n",
    "            step_ret = float(np.clip(step_ret, -self.reward_clip, self.reward_clip))\n",
    "\n",
    "        # NAV 更新 / NAV update\n",
    "        growth = float(np.exp(step_ret))\n",
    "        if not np.isfinite(growth):\n",
    "            growth = 1.0\n",
    "        self.nav *= growth\n",
    "        reward = step_ret\n",
    "\n",
    "        # ===== E) 时间推进与强制平仓落地 / Time advance & enforce flat =====\n",
    "        self.i += 1\n",
    "        terminated = (self.i >= self.end)\n",
    "        truncated = False\n",
    "\n",
    "        # 若触发强平，则把下一步的目标仓位重置为 0，并清空跟踪器\n",
    "        if forced_flat:\n",
    "            self.position = 0.0\n",
    "            self.entry_price = None\n",
    "            self.entry_sign = 0\n",
    "            self.peak_price = None\n",
    "            self.trough_price = None\n",
    "\n",
    "        info = {\n",
    "            \"nav\": float(self.nav),\n",
    "            \"pos\": float(self.position),\n",
    "            \"forced_flat\": bool(forced_flat),\n",
    "        }\n",
    "        return self._get_obs(), reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1751ab6ccb4ea5a",
   "metadata": {},
   "source": [
    "### Part 3: DRL Training\n",
    "\n",
    "This part configures and trains the reinforcement learning agent using the A2C algorithm.\n",
    "\n",
    "- **Feature Selection**:\n",
    "  Choose the normalized `*_norm` columns from the preprocessed dataset as the input features for the environment.\n",
    "\n",
    "- **Environment Setup**:\n",
    "  Construct training and testing environments (`DummyVecEnv`) based on `MinuteTradingEnv`, with a window size of 60 to match the normalization window.\n",
    "\n",
    "- **Model Configuration**:\n",
    "  Initialize the A2C agent with an MLP policy. Define key hyperparameters such as learning rate, rollout length (`n_steps`), discount factor (`gamma`), GAE lambda, and gradient clipping.\n",
    "\n",
    "- **Training and Saving**:\n",
    "  Train the model for 1,000,000 timesteps and save the trained policy to a file for later evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89a37e13520c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:52:29.164098Z",
     "start_time": "2025-09-04T10:39:34.894405Z"
    }
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "\n",
    "# ===== 1) 选环境用的特征列 / Select feature columns for environment =====\n",
    "# 使用预处理生成的 *_norm 列 / Use the normalized *_norm columns generated in preprocessing\n",
    "feat_cols_env = [c for c in train_df.columns if c.endswith(\"_norm\")]\n",
    "\n",
    "# 如果想把原始 OHLCV 也一起喂给模型（一般不需要），可这样并入：\n",
    "# If you also want to feed raw OHLCV (usually not necessary), uncomment:\n",
    "# feat_cols_env = feat_cols_env + [\"open\", \"high\", \"low\", \"close\", \"volume\"]\n",
    "\n",
    "# 安全检查：不能有空列或 NaN/Inf / Sanity checks: ensure no empty list and no NaN/Inf\n",
    "assert len(feat_cols_env) > 0, \"No *_norm feature columns found for the environment.\"\n",
    "for name, df_ in [(\"train_df\", train_df), (\"test_df\", test_df)]:\n",
    "    X = df_[feat_cols_env].to_numpy()\n",
    "    if not np.isfinite(X).all():\n",
    "        bad_cols = [c for c in feat_cols_env if not np.isfinite(df_[c]).all()]\n",
    "        raise ValueError(f\"{name} contains NaN/Inf in selected features: {bad_cols}\")\n",
    "\n",
    "# ===== 2) 可选：初始指标权重 / Optional: initial feature weights =====\n",
    "# 举例：抬高 RSI 权重、略降 MACD、轻微增强布林上轨；名字需与列名完全一致\n",
    "# Example: boost RSI, downweight MACD a bit, slightly boost BB_high. Names must match columns.\n",
    "init_feature_weights = {\n",
    "    \"RSI_norm\": 1,\n",
    "    \"MACD_norm\": 1,\n",
    "    \"BB_high_norm\": 1,\n",
    "}\n",
    "\n",
    "# ===== 3) 构建训练/测试环境（含权重控制） / Build training & test envs (with weights) =====\n",
    "# 保持 window=60，与归一化窗口一致更合理 / Keep window=60 to match normalization window\n",
    "train_env = DummyVecEnv([lambda: MinuteTradingEnv(\n",
    "    train_df, feat_cols_env, window=60,\n",
    "    # === 传入权重控制参数 / pass weight controller params ===\n",
    "    feature_weights=init_feature_weights,\n",
    "    normalize_weights=True,       # 将权重按均值归一，避免整体量级漂移 / normalize weights by mean\n",
    "    # （可选）止损与风控参数 / optional risk-control params\n",
    "    # stop_loss_pct=0.02, trailing_stop_pct=0.03,\n",
    ")])\n",
    "test_env  = DummyVecEnv([lambda: MinuteTradingEnv(\n",
    "    test_df,  feat_cols_env, window=60,\n",
    "    feature_weights=init_feature_weights,\n",
    "    normalize_weights=True,\n",
    ")])\n",
    "\n",
    "# ===== 4) （可选）训练期动态调权回调 / Optional: dynamic feature-weight scheduler =====\n",
    "# 用法：每次回调被触发时，根据当前 timesteps 返回要调整的权重字典\n",
    "# Usage: at each callback, compute a dict of weights to update\n",
    "\n",
    "def weight_schedule(total_steps_done: int) -> dict:\n",
    "    \"\"\"\n",
    "    根据已训练步数返回‘增量权重’（只更新给出的键）；\n",
    "    Return a partial dict of weights to update.\n",
    "    例：前 300k 步逐步提高 RSI 权重到 1.8；之后维持不变。\n",
    "    \"\"\"\n",
    "    # Linear warm-up from 1.5 -> 1.8 in first 300k steps (given we started at 1.5)\n",
    "    target_rsi = 1.5 + 0.3 * min(total_steps_done, 300_000) / 300_000\n",
    "    return {\"RSI_norm\": float(target_rsi)}\n",
    "\n",
    "class FeatureWeightScheduler(BaseCallback):\n",
    "    \"\"\"\n",
    "    简单的调权回调：每次 rollout 结束后调用调度函数，并更新环境的特征权重。\n",
    "    Simple callback to update feature weights after each rollout.\n",
    "    \"\"\"\n",
    "    def __init__(self, schedule_fn, normalize=True, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.schedule_fn = schedule_fn\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        steps = int(self.model.num_timesteps)\n",
    "        new_w = self.schedule_fn(steps)\n",
    "        # 由于我们用的是 DummyVecEnv，取第 0 个子环境更新即可\n",
    "        self.training_env.envs[0].set_feature_weights(new_w, normalize=self.normalize)\n",
    "        return None\n",
    "\n",
    "fw_scheduler = FeatureWeightScheduler(weight_schedule, normalize=True)\n",
    "\n",
    "# ===== 5) 配置 A2C 模型 / Configure A2C model =====\n",
    "# 给一点熵（ent_coef）以增强探索，避免动作长期粘在边界\n",
    "model = A2C(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=train_env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=5 * 60,      # 每次 rollout 步数 ~5 小时 / rollout length (~5 hours)\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.01,       # ↑ add exploration; was 0.0\n",
    "    vf_coef=0.5,\n",
    "    max_grad_norm=0.5,\n",
    "    verbose=1,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# ===== 6) 训练与保存模型 / Train and save the model =====\n",
    "# 如果不想动态调权，把 callback=fw_scheduler 去掉即可\n",
    "model.learn(total_timesteps=1_000_000, callback=fw_scheduler)  # 先跑 1e6 步感受一下 / run 1e6 steps\n",
    "model.save(\"a2c_ethusdt_1m_no_sentiment.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab39d8e132c5b3c",
   "metadata": {},
   "source": [
    "### Part 4: Evaluation\n",
    "\n",
    "This part evaluates the trained agent on the test environment and reports detailed performance metrics and plots.\n",
    "\n",
    "- **Rollout & Logging**:\n",
    "  Run the trained policy on the test environment to collect NAV, position, and per-step rewards. Detect trades using a small position-change threshold to avoid counting floating-point jitter as trades.\n",
    "\n",
    "- **Metrics**:\n",
    "  Compute Final NAV, CAGR (by steps-per-year), Sharpe ratio (risk-free = 0), and Max Drawdown (based on NAV). Aggregate trade-level statistics (trade count, win rate, average win/loss).\n",
    "\n",
    "- **Visualization**:\n",
    "  Plot the equity curve (NAV) and the position time series to provide an intuitive view of behavior and performance.\n",
    "\n",
    "- **Reproducibility Notes**:\n",
    "  Use the same feature set as training (e.g., `*_norm` columns) and the same window length. Set `periods_per_year` to 525,600 for crypto 1-minute data (24×7) or ~98,280 for US equities (252 trading days × 390 minutes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849ff36fa48a176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T10:55:10.552748Z",
     "start_time": "2025-09-04T10:53:47.859892Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# ===== 1) 定义评估函数 / Define evaluation function =====\n",
    "def evaluate_detailed(model, env,\n",
    "                      periods_per_year: float = 525_600,\n",
    "                      trade_eps: float = 1e-2):\n",
    "    \"\"\"\n",
    "    periods_per_year: 年化步数 / Annualized steps\n",
    "        - Crypto 1-min ≈ 525,600 (24×7)\n",
    "        - US equities 1-min ≈ 98,280 (=252*390)\n",
    "    trade_eps: 判定调仓阈值，避免把浮点微抖当成一次交易\n",
    "               Threshold to detect position changes and avoid jitter trades\n",
    "    \"\"\"\n",
    "    # ===== 2) 初始化状态 / Initialize state =====\n",
    "    obs, _ = env.reset()\n",
    "    done = truncated = False\n",
    "\n",
    "    navs, poss, rewards = [], [], []\n",
    "    trade_rets = []\n",
    "    last_pos = 0.0\n",
    "    entry_nav = None\n",
    "\n",
    "    # ===== 3) 策略回放 / Roll out policy on env =====\n",
    "    while not (done or truncated):\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "        nav = float(info[\"nav\"])\n",
    "        pos = float(info[\"pos\"])\n",
    "\n",
    "        navs.append(nav)\n",
    "        poss.append(pos)\n",
    "        rewards.append(float(reward))\n",
    "\n",
    "        # —— 交易事件检测 / Detect trade events ——\n",
    "        if abs(pos - last_pos) > trade_eps:\n",
    "            is_flat_now = abs(pos) <= trade_eps\n",
    "            was_flat    = abs(last_pos) <= trade_eps\n",
    "\n",
    "            if was_flat and not is_flat_now:\n",
    "                # 开仓 / Open position\n",
    "                entry_nav = nav\n",
    "            elif (not was_flat) and is_flat_now and (entry_nav is not None):\n",
    "                # 平仓 / Close position\n",
    "                trade_rets.append(nav / entry_nav - 1.0)\n",
    "                entry_nav = None\n",
    "            elif np.sign(last_pos) != np.sign(pos) and (entry_nav is not None):\n",
    "                # 反手：先结算旧单，再以当前 NAV 为新开仓成本\n",
    "                # Reverse: close old trade then reopen\n",
    "                trade_rets.append(nav / entry_nav - 1.0)\n",
    "                entry_nav = nav\n",
    "\n",
    "        last_pos = pos\n",
    "\n",
    "    navs = np.asarray(navs, dtype=float)\n",
    "    poss = np.asarray(poss, dtype=float)\n",
    "\n",
    "    # ===== 4) 期末强制结算 / Force-close remaining position at the end =====\n",
    "    if entry_nav is not None and navs.size:\n",
    "        trade_rets.append(navs[-1] / entry_nav - 1.0)\n",
    "        entry_nav = None\n",
    "\n",
    "    # ===== 5) 计算绩效指标 / Compute performance metrics =====\n",
    "    # Step returns from NAV\n",
    "    if navs.size >= 2:\n",
    "        rets = navs[1:] / navs[:-1] - 1.0\n",
    "    else:\n",
    "        rets = np.array([], dtype=float)\n",
    "\n",
    "    # Sharpe (annualized, rf=0)\n",
    "    if rets.size > 1 and np.isfinite(rets).all():\n",
    "        mu = rets.mean()\n",
    "        sigma = rets.std(ddof=1)\n",
    "        sharpe = (mu / sigma) * np.sqrt(periods_per_year) if sigma > 0 else np.nan\n",
    "    else:\n",
    "        sharpe = np.nan\n",
    "\n",
    "    # Max Drawdown (positive magnitude)\n",
    "    if navs.size > 0:\n",
    "        roll_max = np.maximum.accumulate(navs)\n",
    "        dd = navs / roll_max - 1.0\n",
    "        maxdd = float(abs(dd.min()))\n",
    "    else:\n",
    "        maxdd = np.nan\n",
    "\n",
    "    # CAGR by duration (steps / periods_per_year)\n",
    "    if navs.size > 1:\n",
    "        years = len(navs) / periods_per_year\n",
    "        cagr = (navs[-1] / navs[0]) ** (1.0 / years) - 1.0 if years > 0 else np.nan\n",
    "    else:\n",
    "        cagr = np.nan\n",
    "\n",
    "    # ===== 6) 交易统计 / Trade statistics =====\n",
    "    n_trades = len(trade_rets)\n",
    "    if n_trades > 0:\n",
    "        wins = [r for r in trade_rets if r > 0]\n",
    "        losses = [r for r in trade_rets if r <= 0]\n",
    "        win_rate = len(wins) / n_trades if n_trades else np.nan\n",
    "        avg_win = float(np.mean(wins)) if wins else np.nan\n",
    "        avg_loss = float(np.mean(losses)) if losses else np.nan\n",
    "    else:\n",
    "        win_rate = np.nan\n",
    "        avg_win = np.nan\n",
    "        avg_loss = np.nan\n",
    "\n",
    "    metrics = {\n",
    "        \"FinalNAV\": float(navs[-1]) if navs.size else np.nan,\n",
    "        \"CAGR\": float(cagr) if np.isfinite(cagr) else np.nan,\n",
    "        \"Sharpe\": float(sharpe) if np.isfinite(sharpe) else np.nan,\n",
    "        \"MaxDD\": float(maxdd) if np.isfinite(maxdd) else np.nan,\n",
    "        \"Trades\": int(n_trades),\n",
    "        \"WinRate\": float(win_rate) if np.isfinite(win_rate) else np.nan,\n",
    "        \"AvgWin\": float(avg_win) if np.isfinite(avg_win) else np.nan,\n",
    "        \"AvgLoss\": float(avg_loss) if np.isfinite(avg_loss) else np.nan,\n",
    "        \"AvgPos\": float(np.mean(np.abs(poss))) if poss.size else np.nan,\n",
    "    }\n",
    "\n",
    "    # ===== 7) 可视化 / Visualization =====\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Equity curve\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(navs, label=\"NAV\")\n",
    "    plt.title(\"Equity Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Position over time\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(poss, label=\"Position\")\n",
    "    plt.title(\"Position over Time\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ===== 8) 使用示例 / Usage example =====\n",
    "# 注意：这里用的是 feat_cols_env（与训练一致），而不是旧的 feat_cols\n",
    "# Note: use feat_cols_env (same features as training), not the old feat_cols\n",
    "test_env = MinuteTradingEnv(\n",
    "    test_df, feat_cols_env, window=60,\n",
    "    fee_rate=0.0005, slippage=0.0002, pos_change_penalty=0.001\n",
    ")\n",
    "\n",
    "metrics = evaluate_detailed(model, test_env, periods_per_year=525_600, trade_eps=1e-2)\n",
    "\n",
    "# 用 json 打印避免“0,”小数点渲染问题 / safer printing\n",
    "print(json.dumps(metrics, indent=2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

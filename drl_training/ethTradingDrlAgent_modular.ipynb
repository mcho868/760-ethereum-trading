{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DRL Trading System Modules\n",
        "\n",
        "This document provides a simple overview of the modular \n",
        "components in the DRL trading system.\n",
        "\n",
        "🏗️ Modular Architecture\n",
        "\n",
        "The system is organized into the following modules:\n",
        "\n",
        "1. ConfigManager: Centralizes all configuration settings for \n",
        "    the system.\n",
        "2. DataProcessor: Handles data loading, preprocessing, and \n",
        "    feature engineering.\n",
        "3. StateActionReward: Defines the state space, action space, \n",
        "    and the logic for reward calculation.\n",
        "4. TradingEnvironment: Provides the modular trading environment\n",
        "    where the agent operates.\n",
        "5. ModelTrainer: Manages the training of A2C and TD3 models.\n",
        "6. PerformanceAnalyzer: Conducts performance analysis and \n",
        "    creates visualizations of the results.\n",
        "7. HyperparameterOptimizer: Implements strategies for \n",
        "    hyperparameter optimization.\n",
        "8. RollingWindowTrainer: Manages the rolling window training \n",
        "    and validation process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15-Day State Space Methodology with Rolling Window Training\n",
        "\n",
        "This notebook implements the complete DRL trading methodology from the original research\n",
        "\n",
        "### 📋 **Complete Workflow**\n",
        "1. **Data Loading & Feature Engineering** - Load and process ETH data with 15D features\n",
        "2. **Rolling Window Diagnostics** - Train on rolling windows for initial evaluation and eval set testing to finalise the hyperparameter\n",
        "3. **Full Training with Validation** - Complete training with proper validation scoring\n",
        "4. **Final Testing & Analysis** - Comprehensive evaluation on test set with visualizations\n",
        "\n",
        "### 🎯 **Key Features**\n",
        "- ✅ Complete 15D state space as per methodology\n",
        "- ✅ Multi-component reward function optimization\n",
        "- ✅ Rolling window training protocol\n",
        "- ✅ Comprehensive hyperparameter testing\n",
        "- ✅ Advanced risk management\n",
        "- ✅ Temporal data splitting\n",
        "- ✅ Modular architecture for maintainability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports loaded successfully\n",
            "🎲 Random seed set to: 42\n",
            "🐍 Python version: 3.12.5 (v3.12.5:ff3bc82f7c9, Aug  7 2024, 05:32:06) [Clang 13.0.0 (clang-1300.0.29.30)]\n",
            "📊 NumPy version: 2.3.2\n",
            "🐼 Pandas version: 2.3.2\n",
            "🏋️ Gymnasium version: 1.2.0\n",
            "🧠 Stable-Baselines3 available\n",
            "\n",
            "🔧 Configuration Summary\n",
            "==================================================\n",
            "📊 State Space Dimensions: 15D\n",
            "   - Core Features: 6D (Position, Z-score, Zone, Price Momentum, Z-score Momentum, Position Change)\n",
            "   - Technical Indicators: 8D (MACD×3, RSI×1, BB×3, OBV×1)\n",
            "   - Sentiment Data: 1D (Reddit Sentiment)\n",
            "💰 Trading Configuration:\n",
            "   - Initial Capital: $10,000\n",
            "   - Episode Length: 10,080 minutes\n",
            "   - Max Position Shift: 0.1 per minute\n",
            "🎯 Reward Function: Multi-component hybrid (6 components)\n",
            "📅 Training Protocol: Rolling window (6 months)\n",
            "💻 Parallel Processing: 8 cores\n",
            "🔄 Sentiment Integration: Enabled\n",
            "📁 Output Directory: ./processed_data_15d\n",
            "🔍 Environment: default\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# ===================== COMPLETE IMPORTS & CONFIGURATION =====================\n",
        "\n",
        "# Core libraries\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Tuple, Optional, Any, Union\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning & Deep Reinforcement Learning\n",
        "import torch\n",
        "import gymnasium as gym\n",
        "from stable_baselines3 import A2C, TD3\n",
        "from stable_baselines3.common.utils import set_random_seed\n",
        "\n",
        "# Visualization & Analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "# Statistical Analysis\n",
        "from scipy import stats\n",
        "\n",
        "# Progress tracking\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Modular components\n",
        "sys.path.append('./modules')\n",
        "from modules import (\n",
        "    ConfigManager,\n",
        "    DataProcessor,\n",
        "    StateActionReward,\n",
        "    TradingEnvironment,\n",
        "    ModelTrainer,\n",
        "    PerformanceAnalyzer,\n",
        "    HyperparameterOptimizer,\n",
        "    RollingWindowTrainer\n",
        ")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "set_random_seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (15, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✅ All imports loaded successfully\")\n",
        "print(f\"🎲 Random seed set to: {RANDOM_SEED}\")\n",
        "print(f\"🐍 Python version: {sys.version}\")\n",
        "print(f\"📊 NumPy version: {np.__version__}\")\n",
        "print(f\"🐼 Pandas version: {pd.__version__}\")\n",
        "print(f\"🏋️ Gymnasium version: {gym.__version__}\")\n",
        "print(f\"🧠 Stable-Baselines3 available\")\n",
        "\n",
        "# Initialize global configuration\n",
        "config = ConfigManager()\n",
        "config.print_summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🚀 **Step 1: Data Loading & Feature Engineering (15D State Space)**\n",
        "\n",
        "Load ETH data and create the complete 15-dimensional feature set as per methodology.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting data loading and feature engineering...\n",
            "🚀 Starting complete data processing pipeline...\n",
            "📁 Loading data from: ../ETHUSDT_1m_with_indicators.parquet\n",
            "   🔧 Found timestamp in index, converting to column\n",
            "   ✅ Loaded 1,883,407 rows of data\n",
            "   📊 Columns: ['ts', 'open', 'high', 'low', 'close', 'volume', 'number_of_trades', 'symbol', 'RSI', 'BB_mid', 'BB_high', 'BB_low', 'EMA_12', 'EMA_26', 'MACD', 'MACD_signal', 'MACD_diff', 'ATR']\n",
            "   📅 Date range: 2022-01-01 00:33:00+00:00 to 2025-07-31 23:59:00+00:00\n",
            "\n",
            "🔧 Feature Engineering Pipeline (15D State Space):\n",
            "   🔬 Calculating core features (4D + 2D by environment)...\n",
            "      ✅ Z-score range: [-10.32, 10.36]\n",
            "      ✅ Zone distribution: {0.0: 569097, -0.5: 568471, 0.5: 566294, -1.0: 92863, 1.0: 86682}\n",
            "      ✅ Price momentum range: [-0.0959, 0.0635]\n",
            "   📈 Calculating technical indicators (8D)...\n",
            "      📊 Full OHLCV data available - calculating comprehensive indicators\n",
            "      ✅ Technical indicators calculated and normalized\n",
            "   🔄 Integrating sentiment data (1D)...\n",
            "      ✅ Sentiment merged – coverage: 100.0%\n",
            "\n",
            "✅ All 15D features successfully calculated!\n",
            "🔄 Creating temporal data splits (70/15/15)...\n",
            "   ✅ Training:   1,318,384 rows (70.0%)\n",
            "   ✅ Validation: 282,511 rows (15.0%)\n",
            "   ✅ Test:       282,512 rows (15.0%)\n",
            "   📅 Training period:   2022-01-01 to 2024-07-04\n",
            "   📅 Validation period: 2024-07-04 to 2025-01-16\n",
            "   📅 Test period:       2025-01-16 to 2025-07-31\n",
            "   💾 Processed data saved: ./processed_data_15d/processed_eth_data_15d.parquet\n",
            "   💾 Data splits saved to: ./processed_data_15d\n",
            "\n",
            "📊 Data Processing Summary:\n",
            "   📈 Raw data: 1,883,407 rows\n",
            "   🔧 Processed data: 1,883,407 rows\n",
            "   📋 Features: 13 dimensions\n",
            "   🎯 State space: 15D (as per methodology)\n",
            "   💾 Memory usage: 533.5 MB\n",
            "\n",
            "📋 Sample of 15D Feature Data:\n",
            "          z_score  zone_norm  price_momentum  z_score_momentum      macd  \\\n",
            "1883402 -0.100069        0.0        0.000898          0.345595 -0.305405   \n",
            "1883403  0.109267        0.0        0.000541          0.209336 -0.237294   \n",
            "1883404 -0.046648        0.0       -0.000438         -0.155915 -0.197820   \n",
            "1883405 -0.477679        0.0       -0.001238         -0.431031 -0.212083   \n",
            "1883406 -0.060336        0.0        0.001050          0.417343 -0.180113   \n",
            "\n",
            "         macd_signal  macd_histogram       rsi  bb_middle  bb_upper  bb_lower  \\\n",
            "1883402    -0.471293        0.455547 -0.033035   0.851316  0.850257  0.852098   \n",
            "1883403    -0.428076        0.550241  0.046707   0.851349  0.850375  0.852046   \n",
            "1883404    -0.385111        0.546953 -0.021522   0.851528  0.850650  0.852129   \n",
            "1883405    -0.353772        0.396004 -0.202000   0.851491  0.850625  0.852080   \n",
            "1883406    -0.321904        0.402852 -0.034044   0.851574  0.850773  0.852097   \n",
            "\n",
            "              obv  sentiment_score  \n",
            "1883402 -0.729490         0.084228  \n",
            "1883403 -0.729366         0.084228  \n",
            "1883404 -0.729553         0.084228  \n",
            "1883405 -0.729614         0.084228  \n",
            "1883406 -0.728610         0.084228  \n",
            "\n",
            "🎯 Data ready for 15D state space training!\n",
            "\n",
            "📊 Feature Engineering Summary:\n",
            "   📈 Processed data: 1,883,407 rows\n",
            "   📋 Features: 13 dimensions\n",
            "   🎯 State space: 15D (as per methodology)\n",
            "   💾 Memory usage: 533.5 MB\n",
            "\n",
            "📋 Sample of 15D Feature Data:\n",
            "          z_score  zone_norm  price_momentum  z_score_momentum      macd  \\\n",
            "1883404 -0.046648        0.0       -0.000438         -0.155915 -0.197820   \n",
            "1883405 -0.477679        0.0       -0.001238         -0.431031 -0.212083   \n",
            "1883406 -0.060336        0.0        0.001050          0.417343 -0.180113   \n",
            "\n",
            "         macd_signal  macd_histogram       rsi  bb_middle  bb_upper  bb_lower  \\\n",
            "1883404    -0.385111        0.546953 -0.021522   0.851528  0.850650  0.852129   \n",
            "1883405    -0.353772        0.396004 -0.202000   0.851491  0.850625  0.852080   \n",
            "1883406    -0.321904        0.402852 -0.034044   0.851574  0.850773  0.852097   \n",
            "\n",
            "              obv  sentiment_score  \n",
            "1883404 -0.729553         0.084228  \n",
            "1883405 -0.729614         0.084228  \n",
            "1883406 -0.728610         0.084228  \n",
            "\n",
            "✅ Data processing complete!\n",
            "📅 Ready for temporal data splitting...\n"
          ]
        }
      ],
      "source": [
        "# ===================== DATA LOADING & FEATURE ENGINEERING =====================\n",
        "\n",
        "print(\"🚀 Starting data loading and feature engineering...\")\n",
        "\n",
        "# Initialize data processor\n",
        "data_processor = DataProcessor(config)\n",
        "\n",
        "# Run complete feature engineering pipeline\n",
        "df_processed, feature_columns, data_splits = data_processor.run_full_pipeline(config.data.data_path)\n",
        "\n",
        "print(f\"\\n📊 Feature Engineering Summary:\")\n",
        "print(f\"   📈 Processed data: {len(df_processed):,} rows\") \n",
        "print(f\"   📋 Features: {len(feature_columns)} dimensions\")\n",
        "print(f\"   🎯 State space: 15D (as per methodology)\")\n",
        "print(f\"   💾 Memory usage: {df_processed.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
        "\n",
        "# Display sample of processed features\n",
        "print(f\"\\n📋 Sample of 15D Feature Data:\")\n",
        "sample_features = df_processed[feature_columns].tail(3)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "print(sample_features)\n",
        "pd.reset_option('display.max_columns')\n",
        "pd.reset_option('display.width')\n",
        "\n",
        "print(f\"\\n✅ Data processing complete!\")\n",
        "print(f\"📅 Ready for temporal data splitting...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 Extracting Data Splits from Pipeline Results...\n",
            "\n",
            "✅ Temporal data splitting complete!\n",
            "   📈 Training:   1,318,384 rows (70.0%)\n",
            "   📊 Validation: 282,511 rows (15.0%)\n",
            "   📉 Test:       282,512 rows (15.0%)\n",
            "🖥️ Using MPS device\n",
            "✅ ModelTrainer initialized\n",
            "   📊 Training data: 1,318,384 rows\n",
            "   📊 Validation data: 282,511 rows\n",
            "   📊 Test data: 282,512 rows\n",
            "   🎯 Features: 13 dimensions\n",
            "   🏛️ Environment: Modular TradingEnvironment\n",
            "\n",
            "🧠 ModelTrainer initialized and ready!\n",
            "🎯 Ready for rolling window training implementation\n"
          ]
        }
      ],
      "source": [
        "# ===================== TEMPORAL DATA SPLITTING =====================\n",
        "\n",
        "print(\"\\n📊 Extracting Data Splits from Pipeline Results...\")\n",
        "\n",
        "# Extract data splits (already created by run_full_pipeline)\n",
        "train_data = data_splits['train']\n",
        "val_data = data_splits['validation'] \n",
        "test_data = data_splits['test']\n",
        "\n",
        "print(f\"\\n✅ Temporal data splitting complete!\")\n",
        "print(f\"   📈 Training:   {len(train_data):,} rows ({len(train_data)/len(df_processed):.1%})\")\n",
        "print(f\"   📊 Validation: {len(val_data):,} rows ({len(val_data)/len(df_processed):.1%})\")\n",
        "print(f\"   📉 Test:       {len(test_data):,} rows ({len(test_data)/len(df_processed):.1%})\")\n",
        "\n",
        "# Initialize model trainer with data splits\n",
        "# CPU seems to be faster on MAC, but don't know about nvidia gpus. I think you can test with max parallel workers > 1 for gpui if you have more vram. \n",
        "trainer = ModelTrainer(train_data, val_data, test_data, feature_columns, config, device=\"cpu\")\n",
        "\n",
        "print(f\"\\n🧠 ModelTrainer initialized and ready!\")\n",
        "print(f\"🎯 Ready for rolling window training implementation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 **Step 3: Full Training with Real Validation Scoring**\n",
        "\n",
        "Based on the rolling window diagnostics results, we now proceed with full training on the complete training dataset, using the validation set for hyperparameter selection and model evaluation. This follows the exact methodology from the original implementation with improved modular architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧠 Starting Full Training with Hyperparameter Optimization...\n",
            "   ⚠️ MPS device detected. Setting max_parallel_jobs to 1 to ensure efficient GPU utilization.\n",
            "   ⚠️ GPU mps) detected. Setting max_parallel_jobs to 1 to ensure efficient GPU utilization.\n",
            "✅ HyperparameterOptimizer initialized\n",
            "   💻 Max parallel jobs: 15\n",
            "   📊 Performance metric: sharpe_ratio\n",
            "   📁 Output directory: processed_data_15d/optimization_results\n",
            "   ✅ Loaded 202 configurations from ./drl_training_configs.json\n",
            "   📊 Algorithms: ['A2C']\n",
            "🔪 Starting Phase 1: Culling 11 configurations with rolling window diagnostics...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating Stability:   0%|          | 0/11 [00:00<?, ?it/s]Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0001_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0002_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "/Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0003_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Rolling Windows:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0004_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0005_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0006_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0007_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0008_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0009_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0010_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Rolling Windows:   0%|          | 0/3 [00:00<?, ?it/s]Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ RollingWindowTrainer initialized\n",
            "🔄 Starting rolling window diagnostics\n",
            "   📅 Rolling window: 6 months\n",
            "   📊 Evaluation period: 1 months\n",
            "   🔢 Max windows: 3\n",
            "   📏 Window size: 259,200 rows\n",
            "   📏 Eval size: 43,200 rows\n",
            "   📊 Total training data: 1,318,384 rows\n",
            "\n",
            "   📊 Window 1: Training [0:259,200], Eval [259,200:302,400]\n",
            "      📈 Train rows: 259,200, Eval rows: 43,200\n",
            "🚀 Training A2C model: a2c_0011_window_1\n",
            "   📅 Valid episode range: [120, 249119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (259200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: True\n",
            "   💰 Initial capital: $10,000\n",
            "   📅 Valid episode range: [120, 33119]\n",
            "   🎮 Action space: Box(-1.0, 1.0, (1,), float32)\n",
            "   👁️ Observation space: (15,)\n",
            "🏛️ TradingEnvironment initialized:\n",
            "   📊 Data shape: (43200, 31)\n",
            "   📋 Features: 13D\n",
            "   🎯 State space: 15D\n",
            "   ⏱️ Episode length: 10,080 minutes\n",
            "   🔄 Random start: False\n",
            "   💰 Initial capital: $10,000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Window 1/3:   0%|          | 0/3 [00:00<?, ?it/s]     /Users/choemanseung/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run A2C on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "Window 1/3:   0%|          | 0/3 [01:04<?, ?it/s]3<?, ?it/s]\n",
            "\n",
            "Window 1/3:   0%|          | 0/3 [01:09<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:11<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:07<?, ?it/s]\n",
            "\n",
            "Window 1/3:   0%|          | 0/3 [01:08<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:03<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:11<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:05<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:06<?, ?it/s]\n",
            "Window 1/3:   0%|          | 0/3 [01:09<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     19\u001b[39m all_configs = hyperparameter_optimizer.load_configurations()[:MAX_CONFIGS]\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_configs:\n\u001b[32m     22\u001b[39m     \u001b[38;5;66;03m# This single function call now handles the entire process:\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# 1. Culls 90% of configs using a fast, parallelized rolling-window stability test.\u001b[39;00m\n\u001b[32m     24\u001b[39m     \u001b[38;5;66;03m# 2. Runs full, in-depth optimization on the top 10% of survivors.\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m# 3. The results are ranked by performance on the validation set.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     final_ranked_results = \u001b[43mhyperparameter_optimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_and_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_configs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43msurvival_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Keep the top 10% of configurations\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfast_training_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Timesteps for the fast stability check\u001b[39;49;00m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_windows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Number of rolling windows for the stability check\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_parallel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# The best configuration and its results can be extracted for the final testing phase\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m final_ranked_results:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/drl_training/modules/hyperparameter_optimizer.py:149\u001b[39m, in \u001b[36mHyperparameterOptimizer.filter_and_optimize\u001b[39m\u001b[34m(self, configurations, survival_rate, fast_training_timesteps, max_windows, use_parallel)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ProcessPoolExecutor(max_workers=\u001b[38;5;28mself\u001b[39m.max_parallel_jobs) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m    144\u001b[39m         future_to_config = {\n\u001b[32m    145\u001b[39m             executor.submit(\u001b[38;5;28mself\u001b[39m._evaluate_config_stability, config, fast_training_timesteps, max_windows): config\n\u001b[32m    146\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m configurations\n\u001b[32m    147\u001b[39m         }\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture_to_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfigurations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluating Stability\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mall_stability_results\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/4th year/760/760-ethereum-trading/venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:243\u001b[39m, in \u001b[36mas_completed\u001b[39m\u001b[34m(fs, timeout)\u001b[39m\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout < \u001b[32m0\u001b[39m:\n\u001b[32m    239\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[32m    240\u001b[39m                 \u001b[33m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m) futures unfinished\u001b[39m\u001b[33m'\u001b[39m % (\n\u001b[32m    241\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m waiter.lock:\n\u001b[32m    246\u001b[39m     finished = waiter.finished_futures\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# ===================== FULL TRAINING WITH HYPERPARAMETER OPTIMIZATION =====================\n",
        "\n",
        "def merged_reward_config(cfg: Dict[str, Any]) -> Dict[str, float]:\n",
        "    \"\"\"Merge configuration reward components with defaults.\"\"\"\n",
        "    merged = config.to_dict()['reward'].copy()\n",
        "    merged.update(cfg.get(\"reward_components\", {}))\n",
        "    return merged\n",
        "\n",
        "print(\"🧠 Starting Full Training with Hyperparameter Optimization...\")\n",
        "\n",
        "# Configuration option: Set to True to retrain existing models\n",
        "RETRAIN_EXISTING_MODELS = True  # Set to True to delete and retrain existing models\n",
        "MAX_CONFIGS = 11     #use for testing\n",
        "\n",
        "# Initialize hyperparameter optimizer\n",
        "hyperparameter_optimizer = HyperparameterOptimizer(trainer, config)\n",
        "\n",
        "# Load and select configurations to test\n",
        "all_configs = hyperparameter_optimizer.load_configurations()[:MAX_CONFIGS]\n",
        "\n",
        "if all_configs:\n",
        "    # This single function call now handles the entire process:\n",
        "    # 1. Culls 90% of configs using a fast, parallelized rolling-window stability test.\n",
        "    # 2. Runs full, in-depth optimization on the top 10% of survivors.\n",
        "    # 3. The results are ranked by performance on the validation set.\n",
        "    final_ranked_results = hyperparameter_optimizer.filter_and_optimize(\n",
        "        configurations=all_configs,\n",
        "        survival_rate=0.1,          # Keep the top 10% of configurations\n",
        "        fast_training_timesteps=10000,  # Timesteps for the fast stability check\n",
        "        max_windows=3,              # Number of rolling windows for the stability check\n",
        "        use_parallel=True\n",
        "    )\n",
        "\n",
        "    # The best configuration and its results can be extracted for the final testing phase\n",
        "    if final_ranked_results:\n",
        "        best_result = final_ranked_results[0]\n",
        "        best_config = best_result['config']\n",
        "\n",
        "        print(\"\\n\\n🥇 Best Configuration Found After Full Optimization 🥇\")\n",
        "        print(f\"   - Config ID: {best_result['config_id']}\")\n",
        "        print(f\"   - Final Validation Reward: {best_result['train_metrics']['mean_reward']:.4f}\")\n",
        "        print(f\"   - Final Test Reward (for reference): {best_result['mean_test_reward']:.4f}\")\n",
        "        print(f\"   - Sharpe Ratio (on validation): {best_result['sharpe_ratio']:.3f}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No configurations were loaded. Skipping optimization.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 **Step 4: Final Testing & Comprehensive Analysis**\n",
        "\n",
        "This section performs the final evaluation on the held-out test set using the best configuration, and generates comprehensive visualizations and performance analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_config_dict = best_config\n",
        "best_config_id = best_result[\"config_id\"]\n",
        "algo = best_config_dict.get(\"algorithm\", \"A2C\").upper()\n",
        "\n",
        "print(f\"\\n🚀 Retraining the best model for final analysis: {best_config_id}\")\n",
        "\n",
        "# 2) Retrain the single best model using the winning hyperparameters\n",
        "if algo == \"A2C\":\n",
        "    final_model, _ = trainer.train_a2c_model(best_config_dict, save_model=True)\n",
        "elif algo == \"TD3\":\n",
        "    final_model, _ = trainer.train_td3_model(best_config_dict, save_model=True)\n",
        "else:\n",
        "    raise ValueError(f\"Unsupported algorithm for final training: {algo}\")\n",
        "\n",
        "print(\"\\n✅ Final model retrained and saved.\")\n",
        "\n",
        "# 3) Create the final, held-out test environment\n",
        "test_env = trainer.create_environment(\n",
        "    trainer.test_data,\n",
        "    reward_config=best_config_dict.get(\"reward_components\"),\n",
        "    random_start=False,\n",
        ")\n",
        "\n",
        "# 4) Run the comprehensive analysis on the test set\n",
        "print(\"\\n🔄 Running comprehensive analysis on the test set...\")\n",
        "analyzer = PerformanceAnalyzer(config)\n",
        "final_analysis = analyzer.analyze_model_performance(\n",
        "    model=final_model,\n",
        "    env=test_env,\n",
        "    n_episodes=5,  # Using 5 episodes for a more robust final evaluation\n",
        "    config_info={\"config_id\": best_config_id, \"algorithm\": algo},\n",
        ")\n",
        "\n",
        "# 5) Generate final visualizations and a summary report\n",
        "print(\"\\n🎨 Generating final visualizations...\")\n",
        "analyzer.create_performance_plots(final_analysis, save_plots=True, show_plots=True)\n",
        "\n",
        "final_metrics = final_analysis[\"aggregate_metrics\"]\n",
        "print(\"\\n🎉 FINAL RESULTS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"🥇 Best Model: {best_config_id}\")\n",
        "print(f\"🔧 Algorithm: {algo}\")\n",
        "print(f\"📈 Average Total Return: {final_metrics.get('mean_total_return', 0):.2%}\")\n",
        "print(f\"📊 Average Sharpe Ratio: {final_metrics.get('mean_sharpe_ratio', 0):.3f}\")\n",
        "print(f\"📉 Average Max Drawdown: {final_metrics.get('mean_max_drawdown', 0):.2%}\")\n",
        "print(f\"💰 Average Final Portfolio: ${final_metrics.get('mean_final_portfolio_value', 0):,.0f}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\n✅ Complete DRL Trading Analysis Finished!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
